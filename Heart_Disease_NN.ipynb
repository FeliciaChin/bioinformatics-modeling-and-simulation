{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1q_qKIV2t2u"
      },
      "source": [
        "#Import all library needed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,BatchNormalization, Dropout\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "#confusion matrix visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 1. Link notebook with google drive and access data from your personal Gdrive\n",
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "### 2.Set the data path for dataset and model location (ex: model_loc = \"/content/gdrive/My Drive/Dataset/\")\n",
        "dataset_dir = \"/content/gdrive/My Drive/BIOINFORMATICSII/\"\n",
        "model_loc = \"/content/gdrive/My Drive/BIOINFORMATICSII/\"\n",
        "\n",
        "print(os.listdir(dataset_dir))\n",
        "data = pd.read_csv(dataset_dir+'heart.csv')"
      ],
      "metadata": {
        "id": "WazdlOZefP88",
        "outputId": "cbda070c-cfed-43c5-95c5-6d04ec8822ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "['Heart_Disease_NN.ipynb', 'heart.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZADep6q2t3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e04a0d4-08dc-41ab-95d9-e13c3ac560ae"
      },
      "source": [
        "### 3. Insert Exploratory data analysis (EDA) steps to analyze and investigate datasets.\n",
        "print(data.info())\n",
        "print(data.head(10))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trestbps  303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    int64  \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n",
            "None\n",
            "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
            "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
            "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
            "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
            "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
            "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
            "5   57    1   0       140   192    0        1      148      0      0.4      1   \n",
            "6   56    0   1       140   294    0        0      153      0      1.3      1   \n",
            "7   44    1   1       120   263    0        1      173      0      0.0      2   \n",
            "8   52    1   2       172   199    1        1      162      0      0.5      2   \n",
            "9   57    1   2       150   168    0        1      174      0      1.6      2   \n",
            "\n",
            "   ca  thal  target  \n",
            "0   0     1       1  \n",
            "1   0     2       1  \n",
            "2   0     2       1  \n",
            "3   0     2       1  \n",
            "4   0     2       1  \n",
            "5   0     1       1  \n",
            "6   0     2       1  \n",
            "7   0     3       1  \n",
            "8   0     3       1  \n",
            "9   0     2       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ylkru32t27"
      },
      "source": [
        "### 4. What is the purpose of the code that sets a list of categorical variables\n",
        "### in a dataset and then casts those variables to the object data type using the astype() function?\n",
        "\n",
        "catagorialList = ['sex','cp','fbs','restecg','exang','ca','thal']\n",
        "for item in catagorialList:\n",
        "    data[item] = data[item].astype('object') #casting to object"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNbqP4z32t3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04e0463-d0b0-4236-cf91-c80e281def82"
      },
      "source": [
        " ### 5. Create more data by categorical variable into indicator variables using 'get_dummies' function\n",
        "\n",
        "data = pd.get_dummies(data, drop_first=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-11-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-11-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-11-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-11-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-11-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-11-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhlOEgqg2t3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca931d58-cfc6-4161-f798-06e5cffc21b1"
      },
      "source": [
        "### 6. Explain line 3,4 and 5 and print the shape of x and y\n",
        "\n",
        "y = data['target'].values # take target of the value\n",
        "y = y.reshape(y.shape[0],1) # reshape y array into 1 dimension\n",
        "x = data.drop(['target'],axis=1) #drop the  'target' in the x data\n",
        "##\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(303, 21)\n",
            "(303, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEGdOBJu2t3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b02706-a646-4cac-8b8c-215abd0062ee"
      },
      "source": [
        "### 7. Create a simple dataset and demonstrate the normalization code on the simple dataset\n",
        "data = pd.DataFrame({'A':[10,20,30], 'B':[100,200,300], 'C':[1000, 2000, 3000]})\n",
        "print(\"Original Dataset:\")\n",
        "print(data)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset:\n",
            "    A    B     C\n",
            "0  10  100  1000\n",
            "1  20  200  2000\n",
            "2  30  300  3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 8. Describe the heart dataset after implementing the min max normalization\n",
        "#Normalize data (range 0 - 1)\n",
        "minx = np.min(x)\n",
        "maxx = np.max(x)\n",
        "x = (x - minx) / (maxx - minx)\n",
        "x.head()"
      ],
      "metadata": {
        "id": "asoFBQaumuKA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "7f45df8e-ed0b-4d04-8388-eba1176ae712"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age  trestbps      chol   thalach   oldpeak  slope  sex_1  cp_1  cp_2  \\\n",
              "0  0.708333  0.481132  0.244292  0.603053  0.370968    0.0    1.0   0.0   0.0   \n",
              "1  0.166667  0.339623  0.283105  0.885496  0.564516    0.0    1.0   0.0   1.0   \n",
              "2  0.250000  0.339623  0.178082  0.770992  0.225806    1.0    0.0   1.0   0.0   \n",
              "3  0.562500  0.245283  0.251142  0.816794  0.129032    1.0    1.0   1.0   0.0   \n",
              "4  0.583333  0.245283  0.520548  0.702290  0.096774    1.0    0.0   0.0   0.0   \n",
              "\n",
              "   cp_3  ...  restecg_1  restecg_2  exang_1  ca_1  ca_2  ca_3  ca_4  thal_1  \\\n",
              "0   1.0  ...        0.0        0.0      0.0   0.0   0.0   0.0   0.0     1.0   \n",
              "1   0.0  ...        1.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "2   0.0  ...        0.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "3   0.0  ...        1.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "4   0.0  ...        1.0        0.0      1.0   0.0   0.0   0.0   0.0     0.0   \n",
              "\n",
              "   thal_2  thal_3  \n",
              "0     0.0     0.0  \n",
              "1     1.0     0.0  \n",
              "2     1.0     0.0  \n",
              "3     1.0     0.0  \n",
              "4     1.0     0.0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f502b6d3-cdad-486c-b698-64057d146bdc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>cp_3</th>\n",
              "      <th>...</th>\n",
              "      <th>restecg_1</th>\n",
              "      <th>restecg_2</th>\n",
              "      <th>exang_1</th>\n",
              "      <th>ca_1</th>\n",
              "      <th>ca_2</th>\n",
              "      <th>ca_3</th>\n",
              "      <th>ca_4</th>\n",
              "      <th>thal_1</th>\n",
              "      <th>thal_2</th>\n",
              "      <th>thal_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.481132</td>\n",
              "      <td>0.244292</td>\n",
              "      <td>0.603053</td>\n",
              "      <td>0.370968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.283105</td>\n",
              "      <td>0.885496</td>\n",
              "      <td>0.564516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.178082</td>\n",
              "      <td>0.770992</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.251142</td>\n",
              "      <td>0.816794</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.702290</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f502b6d3-cdad-486c-b698-64057d146bdc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f502b6d3-cdad-486c-b698-64057d146bdc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f502b6d3-cdad-486c-b698-64057d146bdc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b3c9fdd1-46cb-4c7b-829c-5d7baa78d5c0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b3c9fdd1-46cb-4c7b-829c-5d7baa78d5c0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b3c9fdd1-46cb-4c7b-829c-5d7baa78d5c0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvykedw82t3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f527985-f428-45a1-8052-fc5f54a2f41a"
      },
      "source": [
        "### 9. Modify the code to split the dataset into train and test (train 70%, val 20% and test 10%).\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "# re-create train and validation set\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "# train 70%, validation 20%, test 10%\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(169, 21)\n",
            "(43, 21)\n",
            "(91, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pwz5A_j2t30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c420f9e1-745b-4306-f182-ee136971f3e4"
      },
      "source": [
        "### 10. What is the purpose of each layer in the neural network created using the Sequential() function with 64, 32, and 1 neurons,\n",
        "### respectively, and softmax and sigmoid activation functions?\n",
        "\n",
        "model = Sequential() #Allow us to create model layer by layer\n",
        "model.add(Dense(64, input_dim=21, activation='softmax')) #Softmax turn number data into probabilities which sum to 1\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.add(Dense(1, activation='sigmoid')) # produce probability value (number between 0 or 1)\n",
        "model.summary()\n",
        "\n",
        "###The first two layers are hidden layers with softmax activation, which are used for feature extraction and learning complex patterns in the data.\n",
        "###The last layer is the output layer with sigmoid activation, which produces the final prediction probabilities for binary classification problems."
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 64)                1408      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3521 (13.75 KB)\n",
            "Trainable params: 3521 (13.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0pM4z_OQfNi"
      },
      "source": [
        "### 11. This code compiles a neural network model with a mean squared error loss function, the Adam optimizer with a learning rate of 0.01,\n",
        "### and accuracy as a performance metric. What does each of these components mean, and how do they affect the model training and performance?\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999,epsilon=1e-07, amsgrad=False,name='Adam'),\n",
        "              metrics=['acc'])\n",
        "# The mean squared error loss function quantifies how well the model's predictions match the actual target values during training.\n",
        "# The choice of loss function affects how the model learns from the data and directly impacts the optimization process.\n",
        "\n",
        "# The Adam optimizer determines how the model's weights are updated during training to minimize the loss function.\n",
        "# Learning rate (0.01 in this case) controls the step size taken during the optimization process. A larger learning rate may result\n",
        "# in faster convergence but can overshoot the minimum, while a smaller learning rate may take longer to converge but may converge to a more precise minimum.\n",
        "# I t help determines how the model's weights are updated during training. Adam optimizer adapts the learning rate for each parameter,\n",
        "# resulting in faster convergence and better performance compared to traditional gradient descent algorithms.\n",
        "\n",
        "# The performance metrics are used to evaluate the performance of the model during training and testing.\n",
        "# It provides insight into how well the model is performing during training and evaluation."
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unxSIBnZ2t36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb67f86b-1fbf-4115-f640-b8c20ba53a01"
      },
      "source": [
        "# start the model training\n",
        "output = []\n",
        "early = EarlyStopping(monitor='val_acc', patience=400, mode='auto')\n",
        "checkpoint = ModelCheckpoint(model_loc+\"heart_disease_best_model.hdf5\", monitor='val_acc', verbose=0, save_best_only=True, mode='auto', save_freq='epoch')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.01, patience=100, verbose=1, mode='auto', min_lr=0.001)\n",
        "callbacks_list = [early]\n",
        "\n",
        "output = model.fit(x_train, y_train,validation_data=(x_val,y_val), epochs=1000, batch_size=16, verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "11/11 [==============================] - 1s 15ms/step - loss: 0.0340 - acc: 0.9645 - val_loss: 0.1919 - val_acc: 0.7907\n",
            "Epoch 2/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0373 - acc: 0.9586 - val_loss: 0.2025 - val_acc: 0.7674\n",
            "Epoch 3/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0403 - acc: 0.9527 - val_loss: 0.1866 - val_acc: 0.7907\n",
            "Epoch 4/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0342 - acc: 0.9645 - val_loss: 0.1931 - val_acc: 0.7907\n",
            "Epoch 5/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0343 - acc: 0.9645 - val_loss: 0.1908 - val_acc: 0.7907\n",
            "Epoch 6/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0326 - acc: 0.9645 - val_loss: 0.1882 - val_acc: 0.7907\n",
            "Epoch 7/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0333 - acc: 0.9645 - val_loss: 0.1920 - val_acc: 0.7907\n",
            "Epoch 8/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0331 - acc: 0.9586 - val_loss: 0.1915 - val_acc: 0.7907\n",
            "Epoch 9/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0323 - acc: 0.9645 - val_loss: 0.1923 - val_acc: 0.7907\n",
            "Epoch 10/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0323 - acc: 0.9645 - val_loss: 0.1919 - val_acc: 0.7907\n",
            "Epoch 11/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0322 - acc: 0.9704 - val_loss: 0.1933 - val_acc: 0.7907\n",
            "Epoch 12/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0330 - acc: 0.9586 - val_loss: 0.1926 - val_acc: 0.7907\n",
            "Epoch 13/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0325 - acc: 0.9645 - val_loss: 0.1919 - val_acc: 0.7907\n",
            "Epoch 14/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0327 - acc: 0.9645 - val_loss: 0.1921 - val_acc: 0.7907\n",
            "Epoch 15/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0330 - acc: 0.9645 - val_loss: 0.1933 - val_acc: 0.7907\n",
            "Epoch 16/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0354 - acc: 0.9586 - val_loss: 0.1840 - val_acc: 0.8140\n",
            "Epoch 17/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0342 - acc: 0.9645 - val_loss: 0.1920 - val_acc: 0.7907\n",
            "Epoch 18/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0335 - acc: 0.9645 - val_loss: 0.1938 - val_acc: 0.7907\n",
            "Epoch 19/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0319 - acc: 0.9645 - val_loss: 0.1930 - val_acc: 0.7907\n",
            "Epoch 20/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0333 - acc: 0.9586 - val_loss: 0.1945 - val_acc: 0.7907\n",
            "Epoch 21/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0321 - acc: 0.9645 - val_loss: 0.1929 - val_acc: 0.7907\n",
            "Epoch 22/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0317 - acc: 0.9704 - val_loss: 0.1939 - val_acc: 0.7907\n",
            "Epoch 23/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0319 - acc: 0.9645 - val_loss: 0.1939 - val_acc: 0.7907\n",
            "Epoch 24/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0327 - acc: 0.9645 - val_loss: 0.1917 - val_acc: 0.7907\n",
            "Epoch 25/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0319 - acc: 0.9645 - val_loss: 0.1922 - val_acc: 0.7907\n",
            "Epoch 26/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0325 - acc: 0.9645 - val_loss: 0.1947 - val_acc: 0.7907\n",
            "Epoch 27/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0316 - acc: 0.9645 - val_loss: 0.1922 - val_acc: 0.7907\n",
            "Epoch 28/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0313 - acc: 0.9704 - val_loss: 0.1905 - val_acc: 0.7907\n",
            "Epoch 29/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0319 - acc: 0.9645 - val_loss: 0.1930 - val_acc: 0.7907\n",
            "Epoch 30/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0308 - acc: 0.9704 - val_loss: 0.1933 - val_acc: 0.7907\n",
            "Epoch 31/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0268 - acc: 0.9763 - val_loss: 0.1923 - val_acc: 0.7907\n",
            "Epoch 32/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0255 - acc: 0.9763 - val_loss: 0.1944 - val_acc: 0.7907\n",
            "Epoch 33/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0258 - acc: 0.9763 - val_loss: 0.1956 - val_acc: 0.7907\n",
            "Epoch 34/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0259 - acc: 0.9763 - val_loss: 0.1952 - val_acc: 0.7907\n",
            "Epoch 35/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0252 - acc: 0.9763 - val_loss: 0.1941 - val_acc: 0.7907\n",
            "Epoch 36/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0263 - acc: 0.9704 - val_loss: 0.1949 - val_acc: 0.7907\n",
            "Epoch 37/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0253 - acc: 0.9763 - val_loss: 0.1950 - val_acc: 0.7907\n",
            "Epoch 38/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0257 - acc: 0.9763 - val_loss: 0.1945 - val_acc: 0.7907\n",
            "Epoch 39/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0253 - acc: 0.9763 - val_loss: 0.1946 - val_acc: 0.7907\n",
            "Epoch 40/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0250 - acc: 0.9763 - val_loss: 0.1938 - val_acc: 0.7907\n",
            "Epoch 41/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0260 - acc: 0.9704 - val_loss: 0.1931 - val_acc: 0.7907\n",
            "Epoch 42/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0259 - acc: 0.9704 - val_loss: 0.1967 - val_acc: 0.7907\n",
            "Epoch 43/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0266 - acc: 0.9704 - val_loss: 0.1934 - val_acc: 0.7907\n",
            "Epoch 44/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0253 - acc: 0.9763 - val_loss: 0.1954 - val_acc: 0.7907\n",
            "Epoch 45/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0247 - acc: 0.9763 - val_loss: 0.1943 - val_acc: 0.7907\n",
            "Epoch 46/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0249 - acc: 0.9763 - val_loss: 0.1951 - val_acc: 0.7907\n",
            "Epoch 47/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0247 - acc: 0.9763 - val_loss: 0.1950 - val_acc: 0.7907\n",
            "Epoch 48/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0250 - acc: 0.9763 - val_loss: 0.1953 - val_acc: 0.7907\n",
            "Epoch 49/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0246 - acc: 0.9763 - val_loss: 0.1958 - val_acc: 0.7907\n",
            "Epoch 50/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0249 - acc: 0.9763 - val_loss: 0.1953 - val_acc: 0.7907\n",
            "Epoch 51/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0247 - acc: 0.9763 - val_loss: 0.1942 - val_acc: 0.7907\n",
            "Epoch 52/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0244 - acc: 0.9763 - val_loss: 0.1956 - val_acc: 0.7907\n",
            "Epoch 53/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0243 - acc: 0.9763 - val_loss: 0.1952 - val_acc: 0.7907\n",
            "Epoch 54/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0244 - acc: 0.9763 - val_loss: 0.1950 - val_acc: 0.7907\n",
            "Epoch 55/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0247 - acc: 0.9763 - val_loss: 0.1946 - val_acc: 0.7907\n",
            "Epoch 56/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0248 - acc: 0.9763 - val_loss: 0.1942 - val_acc: 0.7907\n",
            "Epoch 57/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0262 - acc: 0.9704 - val_loss: 0.1966 - val_acc: 0.7907\n",
            "Epoch 58/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0249 - acc: 0.9763 - val_loss: 0.1936 - val_acc: 0.7907\n",
            "Epoch 59/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0251 - acc: 0.9763 - val_loss: 0.1961 - val_acc: 0.7907\n",
            "Epoch 60/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0241 - acc: 0.9763 - val_loss: 0.1945 - val_acc: 0.7907\n",
            "Epoch 61/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0244 - acc: 0.9763 - val_loss: 0.1956 - val_acc: 0.7907\n",
            "Epoch 62/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0242 - acc: 0.9763 - val_loss: 0.1949 - val_acc: 0.7907\n",
            "Epoch 63/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0240 - acc: 0.9763 - val_loss: 0.1960 - val_acc: 0.7907\n",
            "Epoch 64/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0242 - acc: 0.9763 - val_loss: 0.1959 - val_acc: 0.7907\n",
            "Epoch 65/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0240 - acc: 0.9763 - val_loss: 0.1960 - val_acc: 0.7907\n",
            "Epoch 66/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1982 - val_acc: 0.7907\n",
            "Epoch 67/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0244 - acc: 0.9763 - val_loss: 0.1966 - val_acc: 0.7907\n",
            "Epoch 68/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0251 - acc: 0.9763 - val_loss: 0.1948 - val_acc: 0.7907\n",
            "Epoch 69/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0240 - acc: 0.9763 - val_loss: 0.1969 - val_acc: 0.7907\n",
            "Epoch 70/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1953 - val_acc: 0.7907\n",
            "Epoch 71/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1955 - val_acc: 0.7907\n",
            "Epoch 72/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1959 - val_acc: 0.7907\n",
            "Epoch 73/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1957 - val_acc: 0.7907\n",
            "Epoch 74/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1956 - val_acc: 0.7907\n",
            "Epoch 75/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1962 - val_acc: 0.7907\n",
            "Epoch 76/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1958 - val_acc: 0.7907\n",
            "Epoch 77/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1945 - val_acc: 0.7907\n",
            "Epoch 78/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1962 - val_acc: 0.7907\n",
            "Epoch 79/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1956 - val_acc: 0.7907\n",
            "Epoch 80/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1943 - val_acc: 0.7907\n",
            "Epoch 81/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1966 - val_acc: 0.7907\n",
            "Epoch 82/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1942 - val_acc: 0.7907\n",
            "Epoch 83/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1946 - val_acc: 0.7907\n",
            "Epoch 84/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1949 - val_acc: 0.7907\n",
            "Epoch 85/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1952 - val_acc: 0.7907\n",
            "Epoch 86/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1955 - val_acc: 0.7907\n",
            "Epoch 87/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1940 - val_acc: 0.7907\n",
            "Epoch 88/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1931 - val_acc: 0.7907\n",
            "Epoch 89/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0239 - acc: 0.9763 - val_loss: 0.1966 - val_acc: 0.7907\n",
            "Epoch 90/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1863 - val_acc: 0.7907\n",
            "Epoch 91/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0248 - acc: 0.9763 - val_loss: 0.1898 - val_acc: 0.7907\n",
            "Epoch 92/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0288 - acc: 0.9704 - val_loss: 0.2029 - val_acc: 0.7907\n",
            "Epoch 93/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0277 - acc: 0.9704 - val_loss: 0.1871 - val_acc: 0.8140\n",
            "Epoch 94/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0244 - acc: 0.9763 - val_loss: 0.1726 - val_acc: 0.7907\n",
            "Epoch 95/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0241 - acc: 0.9763 - val_loss: 0.1835 - val_acc: 0.8140\n",
            "Epoch 96/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1892 - val_acc: 0.7907\n",
            "Epoch 97/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1910 - val_acc: 0.7907\n",
            "Epoch 98/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1923 - val_acc: 0.7907\n",
            "Epoch 99/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1925 - val_acc: 0.7907\n",
            "Epoch 100/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1908 - val_acc: 0.7907\n",
            "Epoch 101/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1912 - val_acc: 0.7907\n",
            "Epoch 102/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1924 - val_acc: 0.7907\n",
            "Epoch 103/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1900 - val_acc: 0.7907\n",
            "Epoch 104/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1905 - val_acc: 0.7907\n",
            "Epoch 105/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1918 - val_acc: 0.7907\n",
            "Epoch 106/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1925 - val_acc: 0.7907\n",
            "Epoch 107/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1926 - val_acc: 0.7907\n",
            "Epoch 108/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1916 - val_acc: 0.7907\n",
            "Epoch 109/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1912 - val_acc: 0.7907\n",
            "Epoch 110/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1931 - val_acc: 0.7907\n",
            "Epoch 111/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1911 - val_acc: 0.7907\n",
            "Epoch 112/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1937 - val_acc: 0.7907\n",
            "Epoch 113/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1938 - val_acc: 0.7907\n",
            "Epoch 114/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1922 - val_acc: 0.7907\n",
            "Epoch 115/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1924 - val_acc: 0.7907\n",
            "Epoch 116/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1934 - val_acc: 0.7907\n",
            "Epoch 117/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1927 - val_acc: 0.7907\n",
            "Epoch 118/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1915 - val_acc: 0.7907\n",
            "Epoch 119/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1922 - val_acc: 0.7907\n",
            "Epoch 120/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1949 - val_acc: 0.7907\n",
            "Epoch 121/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1930 - val_acc: 0.7907\n",
            "Epoch 122/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1925 - val_acc: 0.7907\n",
            "Epoch 123/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1928 - val_acc: 0.7907\n",
            "Epoch 124/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1939 - val_acc: 0.7907\n",
            "Epoch 125/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1932 - val_acc: 0.7907\n",
            "Epoch 126/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1939 - val_acc: 0.7907\n",
            "Epoch 127/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1926 - val_acc: 0.7907\n",
            "Epoch 128/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1930 - val_acc: 0.7907\n",
            "Epoch 129/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1929 - val_acc: 0.7907\n",
            "Epoch 130/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1928 - val_acc: 0.7907\n",
            "Epoch 131/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1932 - val_acc: 0.7907\n",
            "Epoch 132/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1934 - val_acc: 0.7907\n",
            "Epoch 133/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1940 - val_acc: 0.7907\n",
            "Epoch 134/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1935 - val_acc: 0.7907\n",
            "Epoch 135/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1937 - val_acc: 0.7907\n",
            "Epoch 136/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1934 - val_acc: 0.7907\n",
            "Epoch 137/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1933 - val_acc: 0.7907\n",
            "Epoch 138/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1936 - val_acc: 0.7907\n",
            "Epoch 139/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1938 - val_acc: 0.7907\n",
            "Epoch 140/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1945 - val_acc: 0.7907\n",
            "Epoch 141/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1939 - val_acc: 0.7907\n",
            "Epoch 142/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1934 - val_acc: 0.7907\n",
            "Epoch 143/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1934 - val_acc: 0.7907\n",
            "Epoch 144/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1932 - val_acc: 0.7907\n",
            "Epoch 145/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1938 - val_acc: 0.7907\n",
            "Epoch 146/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1945 - val_acc: 0.7907\n",
            "Epoch 147/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1939 - val_acc: 0.7907\n",
            "Epoch 148/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1938 - val_acc: 0.7907\n",
            "Epoch 149/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1937 - val_acc: 0.7907\n",
            "Epoch 150/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1936 - val_acc: 0.7907\n",
            "Epoch 151/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1942 - val_acc: 0.7907\n",
            "Epoch 152/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1940 - val_acc: 0.7907\n",
            "Epoch 153/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1936 - val_acc: 0.7907\n",
            "Epoch 154/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1942 - val_acc: 0.7907\n",
            "Epoch 155/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1928 - val_acc: 0.7907\n",
            "Epoch 156/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1944 - val_acc: 0.7907\n",
            "Epoch 157/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1940 - val_acc: 0.7907\n",
            "Epoch 158/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1941 - val_acc: 0.7907\n",
            "Epoch 159/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1932 - val_acc: 0.7907\n",
            "Epoch 160/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1938 - val_acc: 0.7907\n",
            "Epoch 161/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1937 - val_acc: 0.7907\n",
            "Epoch 162/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1939 - val_acc: 0.7907\n",
            "Epoch 163/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1934 - val_acc: 0.7907\n",
            "Epoch 164/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1939 - val_acc: 0.7907\n",
            "Epoch 165/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1950 - val_acc: 0.7907\n",
            "Epoch 166/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1918 - val_acc: 0.7907\n",
            "Epoch 167/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1920 - val_acc: 0.7907\n",
            "Epoch 168/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1937 - val_acc: 0.7907\n",
            "Epoch 169/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1935 - val_acc: 0.7907\n",
            "Epoch 170/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1934 - val_acc: 0.7907\n",
            "Epoch 171/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1949 - val_acc: 0.7907\n",
            "Epoch 172/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1941 - val_acc: 0.7907\n",
            "Epoch 173/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1935 - val_acc: 0.7907\n",
            "Epoch 174/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1932 - val_acc: 0.7907\n",
            "Epoch 175/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1929 - val_acc: 0.7907\n",
            "Epoch 176/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1950 - val_acc: 0.7907\n",
            "Epoch 177/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1942 - val_acc: 0.7907\n",
            "Epoch 178/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1928 - val_acc: 0.7907\n",
            "Epoch 179/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1924 - val_acc: 0.7907\n",
            "Epoch 180/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1926 - val_acc: 0.7907\n",
            "Epoch 181/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1911 - val_acc: 0.7907\n",
            "Epoch 182/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1937 - val_acc: 0.7907\n",
            "Epoch 183/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1931 - val_acc: 0.7907\n",
            "Epoch 184/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1934 - val_acc: 0.7907\n",
            "Epoch 185/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1910 - val_acc: 0.7907\n",
            "Epoch 186/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1905 - val_acc: 0.7907\n",
            "Epoch 187/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1916 - val_acc: 0.7907\n",
            "Epoch 188/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1928 - val_acc: 0.7907\n",
            "Epoch 189/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1930 - val_acc: 0.7907\n",
            "Epoch 190/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1919 - val_acc: 0.7907\n",
            "Epoch 191/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1915 - val_acc: 0.7907\n",
            "Epoch 192/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1918 - val_acc: 0.7907\n",
            "Epoch 193/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1914 - val_acc: 0.7907\n",
            "Epoch 194/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1885 - val_acc: 0.7907\n",
            "Epoch 195/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.2001 - val_acc: 0.7907\n",
            "Epoch 196/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0245 - acc: 0.9763 - val_loss: 0.1921 - val_acc: 0.7907\n",
            "Epoch 197/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0245 - acc: 0.9763 - val_loss: 0.1886 - val_acc: 0.7907\n",
            "Epoch 198/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0244 - acc: 0.9763 - val_loss: 0.2005 - val_acc: 0.7674\n",
            "Epoch 199/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0260 - acc: 0.9704 - val_loss: 0.1844 - val_acc: 0.8140\n",
            "Epoch 200/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0263 - acc: 0.9704 - val_loss: 0.2170 - val_acc: 0.7442\n",
            "Epoch 201/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0280 - acc: 0.9704 - val_loss: 0.2121 - val_acc: 0.7674\n",
            "Epoch 202/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0263 - acc: 0.9704 - val_loss: 0.1922 - val_acc: 0.7907\n",
            "Epoch 203/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2087 - val_acc: 0.7674\n",
            "Epoch 204/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0263 - acc: 0.9704 - val_loss: 0.1835 - val_acc: 0.8140\n",
            "Epoch 205/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1915 - val_acc: 0.7907\n",
            "Epoch 206/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1944 - val_acc: 0.7907\n",
            "Epoch 207/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1962 - val_acc: 0.7674\n",
            "Epoch 208/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1977 - val_acc: 0.7674\n",
            "Epoch 209/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1965 - val_acc: 0.7674\n",
            "Epoch 210/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1955 - val_acc: 0.7674\n",
            "Epoch 211/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1947 - val_acc: 0.7674\n",
            "Epoch 212/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1939 - val_acc: 0.7674\n",
            "Epoch 213/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1935 - val_acc: 0.7674\n",
            "Epoch 214/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1936 - val_acc: 0.7674\n",
            "Epoch 215/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1940 - val_acc: 0.7674\n",
            "Epoch 216/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1930 - val_acc: 0.7674\n",
            "Epoch 217/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1929 - val_acc: 0.7674\n",
            "Epoch 218/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1928 - val_acc: 0.7674\n",
            "Epoch 219/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1927 - val_acc: 0.7674\n",
            "Epoch 220/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1922 - val_acc: 0.7674\n",
            "Epoch 221/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1925 - val_acc: 0.7674\n",
            "Epoch 222/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1924 - val_acc: 0.7674\n",
            "Epoch 223/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1926 - val_acc: 0.7674\n",
            "Epoch 224/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1924 - val_acc: 0.7674\n",
            "Epoch 225/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1922 - val_acc: 0.7674\n",
            "Epoch 226/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1925 - val_acc: 0.7674\n",
            "Epoch 227/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1922 - val_acc: 0.7674\n",
            "Epoch 228/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1920 - val_acc: 0.7674\n",
            "Epoch 229/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1920 - val_acc: 0.7674\n",
            "Epoch 230/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1920 - val_acc: 0.7674\n",
            "Epoch 231/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1920 - val_acc: 0.7674\n",
            "Epoch 232/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1913 - val_acc: 0.7674\n",
            "Epoch 233/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1912 - val_acc: 0.7674\n",
            "Epoch 234/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1916 - val_acc: 0.7674\n",
            "Epoch 235/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1910 - val_acc: 0.7674\n",
            "Epoch 236/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1911 - val_acc: 0.7674\n",
            "Epoch 237/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1905 - val_acc: 0.7674\n",
            "Epoch 238/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1890 - val_acc: 0.7907\n",
            "Epoch 239/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1889 - val_acc: 0.7907\n",
            "Epoch 240/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1890 - val_acc: 0.7907\n",
            "Epoch 241/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1902 - val_acc: 0.7674\n",
            "Epoch 242/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1891 - val_acc: 0.7674\n",
            "Epoch 243/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1888 - val_acc: 0.7907\n",
            "Epoch 244/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1893 - val_acc: 0.7907\n",
            "Epoch 245/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1892 - val_acc: 0.7907\n",
            "Epoch 246/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1890 - val_acc: 0.7907\n",
            "Epoch 247/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1891 - val_acc: 0.7907\n",
            "Epoch 248/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1894 - val_acc: 0.7907\n",
            "Epoch 249/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1894 - val_acc: 0.7907\n",
            "Epoch 250/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1894 - val_acc: 0.7907\n",
            "Epoch 251/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1881 - val_acc: 0.7907\n",
            "Epoch 252/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1881 - val_acc: 0.7907\n",
            "Epoch 253/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1884 - val_acc: 0.7907\n",
            "Epoch 254/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1887 - val_acc: 0.7907\n",
            "Epoch 255/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1890 - val_acc: 0.7907\n",
            "Epoch 256/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1878 - val_acc: 0.7907\n",
            "Epoch 257/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1882 - val_acc: 0.7907\n",
            "Epoch 258/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1881 - val_acc: 0.7907\n",
            "Epoch 259/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1876 - val_acc: 0.7907\n",
            "Epoch 260/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1868 - val_acc: 0.7907\n",
            "Epoch 261/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1871 - val_acc: 0.7907\n",
            "Epoch 262/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1881 - val_acc: 0.7907\n",
            "Epoch 263/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1882 - val_acc: 0.7907\n",
            "Epoch 264/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1873 - val_acc: 0.7907\n",
            "Epoch 265/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1870 - val_acc: 0.7907\n",
            "Epoch 266/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1868 - val_acc: 0.7907\n",
            "Epoch 267/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0230 - acc: 0.9763 - val_loss: 0.1867 - val_acc: 0.7907\n",
            "Epoch 268/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0230 - acc: 0.9763 - val_loss: 0.1874 - val_acc: 0.7907\n",
            "Epoch 269/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0230 - acc: 0.9763 - val_loss: 0.1875 - val_acc: 0.7907\n",
            "Epoch 270/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0230 - acc: 0.9763 - val_loss: 0.1868 - val_acc: 0.7907\n",
            "Epoch 271/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0230 - acc: 0.9763 - val_loss: 0.1868 - val_acc: 0.7907\n",
            "Epoch 272/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0230 - acc: 0.9763 - val_loss: 0.1863 - val_acc: 0.7907\n",
            "Epoch 273/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0230 - acc: 0.9763 - val_loss: 0.1869 - val_acc: 0.7907\n",
            "Epoch 274/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0230 - acc: 0.9763 - val_loss: 0.1865 - val_acc: 0.7907\n",
            "Epoch 275/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0230 - acc: 0.9763 - val_loss: 0.1858 - val_acc: 0.7907\n",
            "Epoch 276/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0230 - acc: 0.9763 - val_loss: 0.1860 - val_acc: 0.7907\n",
            "Epoch 277/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0229 - acc: 0.9763 - val_loss: 0.1846 - val_acc: 0.8140\n",
            "Epoch 278/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0229 - acc: 0.9763 - val_loss: 0.1839 - val_acc: 0.8140\n",
            "Epoch 279/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0229 - acc: 0.9763 - val_loss: 0.1839 - val_acc: 0.8140\n",
            "Epoch 280/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0229 - acc: 0.9763 - val_loss: 0.1839 - val_acc: 0.8140\n",
            "Epoch 281/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0229 - acc: 0.9763 - val_loss: 0.1839 - val_acc: 0.8140\n",
            "Epoch 282/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0229 - acc: 0.9763 - val_loss: 0.1836 - val_acc: 0.8140\n",
            "Epoch 283/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0229 - acc: 0.9763 - val_loss: 0.1830 - val_acc: 0.8140\n",
            "Epoch 284/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0228 - acc: 0.9763 - val_loss: 0.1836 - val_acc: 0.8140\n",
            "Epoch 285/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0228 - acc: 0.9763 - val_loss: 0.1835 - val_acc: 0.8140\n",
            "Epoch 286/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0228 - acc: 0.9763 - val_loss: 0.1830 - val_acc: 0.8140\n",
            "Epoch 287/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0228 - acc: 0.9763 - val_loss: 0.1829 - val_acc: 0.8140\n",
            "Epoch 288/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0228 - acc: 0.9763 - val_loss: 0.1831 - val_acc: 0.8140\n",
            "Epoch 289/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0228 - acc: 0.9763 - val_loss: 0.1827 - val_acc: 0.8140\n",
            "Epoch 290/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0228 - acc: 0.9763 - val_loss: 0.1819 - val_acc: 0.8140\n",
            "Epoch 291/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0228 - acc: 0.9763 - val_loss: 0.1816 - val_acc: 0.8140\n",
            "Epoch 292/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0227 - acc: 0.9763 - val_loss: 0.1816 - val_acc: 0.8140\n",
            "Epoch 293/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0227 - acc: 0.9763 - val_loss: 0.1818 - val_acc: 0.8140\n",
            "Epoch 294/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0227 - acc: 0.9763 - val_loss: 0.1821 - val_acc: 0.8140\n",
            "Epoch 295/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0227 - acc: 0.9763 - val_loss: 0.1823 - val_acc: 0.8140\n",
            "Epoch 296/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0227 - acc: 0.9763 - val_loss: 0.1825 - val_acc: 0.8140\n",
            "Epoch 297/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0227 - acc: 0.9763 - val_loss: 0.1825 - val_acc: 0.8140\n",
            "Epoch 298/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0227 - acc: 0.9763 - val_loss: 0.1825 - val_acc: 0.8140\n",
            "Epoch 299/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0226 - acc: 0.9763 - val_loss: 0.1822 - val_acc: 0.8140\n",
            "Epoch 300/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0226 - acc: 0.9763 - val_loss: 0.1814 - val_acc: 0.8140\n",
            "Epoch 301/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0226 - acc: 0.9763 - val_loss: 0.1817 - val_acc: 0.8140\n",
            "Epoch 302/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0226 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.8140\n",
            "Epoch 303/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0226 - acc: 0.9763 - val_loss: 0.1812 - val_acc: 0.8140\n",
            "Epoch 304/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0226 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.8140\n",
            "Epoch 305/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0225 - acc: 0.9763 - val_loss: 0.1813 - val_acc: 0.8140\n",
            "Epoch 306/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0225 - acc: 0.9763 - val_loss: 0.1816 - val_acc: 0.8140\n",
            "Epoch 307/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0225 - acc: 0.9763 - val_loss: 0.1814 - val_acc: 0.8140\n",
            "Epoch 308/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0225 - acc: 0.9763 - val_loss: 0.1811 - val_acc: 0.8140\n",
            "Epoch 309/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0224 - acc: 0.9763 - val_loss: 0.1812 - val_acc: 0.8140\n",
            "Epoch 310/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0224 - acc: 0.9763 - val_loss: 0.1805 - val_acc: 0.8140\n",
            "Epoch 311/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0224 - acc: 0.9763 - val_loss: 0.1802 - val_acc: 0.8140\n",
            "Epoch 312/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0223 - acc: 0.9763 - val_loss: 0.1804 - val_acc: 0.8140\n",
            "Epoch 313/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0222 - acc: 0.9763 - val_loss: 0.1806 - val_acc: 0.8140\n",
            "Epoch 314/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0222 - acc: 0.9763 - val_loss: 0.1809 - val_acc: 0.8140\n",
            "Epoch 315/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0221 - acc: 0.9763 - val_loss: 0.1802 - val_acc: 0.8140\n",
            "Epoch 316/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0221 - acc: 0.9763 - val_loss: 0.1800 - val_acc: 0.8140\n",
            "Epoch 317/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0219 - acc: 0.9763 - val_loss: 0.1800 - val_acc: 0.8140\n",
            "Epoch 318/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0220 - acc: 0.9763 - val_loss: 0.1797 - val_acc: 0.8140\n",
            "Epoch 319/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0216 - acc: 0.9763 - val_loss: 0.1800 - val_acc: 0.8140\n",
            "Epoch 320/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0215 - acc: 0.9763 - val_loss: 0.1802 - val_acc: 0.8140\n",
            "Epoch 321/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0214 - acc: 0.9763 - val_loss: 0.1798 - val_acc: 0.8140\n",
            "Epoch 322/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0214 - acc: 0.9763 - val_loss: 0.1788 - val_acc: 0.8140\n",
            "Epoch 323/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0209 - acc: 0.9763 - val_loss: 0.1800 - val_acc: 0.8140\n",
            "Epoch 324/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0211 - acc: 0.9763 - val_loss: 0.1798 - val_acc: 0.8140\n",
            "Epoch 325/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0206 - acc: 0.9763 - val_loss: 0.1786 - val_acc: 0.8140\n",
            "Epoch 326/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0220 - acc: 0.9763 - val_loss: 0.1807 - val_acc: 0.8140\n",
            "Epoch 327/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0230 - acc: 0.9763 - val_loss: 0.1974 - val_acc: 0.7907\n",
            "Epoch 328/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0220 - acc: 0.9763 - val_loss: 0.1760 - val_acc: 0.8140\n",
            "Epoch 329/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0209 - acc: 0.9763 - val_loss: 0.1818 - val_acc: 0.8140\n",
            "Epoch 330/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0210 - acc: 0.9763 - val_loss: 0.1919 - val_acc: 0.7907\n",
            "Epoch 331/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0242 - acc: 0.9704 - val_loss: 0.1838 - val_acc: 0.8140\n",
            "Epoch 332/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0212 - acc: 0.9763 - val_loss: 0.1843 - val_acc: 0.8140\n",
            "Epoch 333/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0214 - acc: 0.9704 - val_loss: 0.1986 - val_acc: 0.7907\n",
            "Epoch 334/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0196 - acc: 0.9763 - val_loss: 0.1948 - val_acc: 0.7907\n",
            "Epoch 335/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0189 - acc: 0.9763 - val_loss: 0.1875 - val_acc: 0.7907\n",
            "Epoch 336/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0187 - acc: 0.9763 - val_loss: 0.1852 - val_acc: 0.7907\n",
            "Epoch 337/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0184 - acc: 0.9763 - val_loss: 0.1836 - val_acc: 0.8140\n",
            "Epoch 338/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0181 - acc: 0.9763 - val_loss: 0.1811 - val_acc: 0.8140\n",
            "Epoch 339/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0179 - acc: 0.9822 - val_loss: 0.1800 - val_acc: 0.8140\n",
            "Epoch 340/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0178 - acc: 0.9822 - val_loss: 0.1827 - val_acc: 0.7907\n",
            "Epoch 341/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0174 - acc: 0.9822 - val_loss: 0.1825 - val_acc: 0.7907\n",
            "Epoch 342/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0174 - acc: 0.9822 - val_loss: 0.1821 - val_acc: 0.7907\n",
            "Epoch 343/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0171 - acc: 0.9822 - val_loss: 0.1825 - val_acc: 0.7907\n",
            "Epoch 344/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0173 - acc: 0.9822 - val_loss: 0.1834 - val_acc: 0.7907\n",
            "Epoch 345/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0167 - acc: 0.9822 - val_loss: 0.1848 - val_acc: 0.7907\n",
            "Epoch 346/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0168 - acc: 0.9822 - val_loss: 0.1842 - val_acc: 0.7907\n",
            "Epoch 347/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0166 - acc: 0.9822 - val_loss: 0.1857 - val_acc: 0.7907\n",
            "Epoch 348/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0164 - acc: 0.9822 - val_loss: 0.1844 - val_acc: 0.7907\n",
            "Epoch 349/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0163 - acc: 0.9822 - val_loss: 0.1843 - val_acc: 0.7907\n",
            "Epoch 350/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0162 - acc: 0.9822 - val_loss: 0.1862 - val_acc: 0.7907\n",
            "Epoch 351/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0161 - acc: 0.9822 - val_loss: 0.1859 - val_acc: 0.7907\n",
            "Epoch 352/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0161 - acc: 0.9822 - val_loss: 0.1999 - val_acc: 0.7674\n",
            "Epoch 353/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0159 - acc: 0.9822 - val_loss: 0.1851 - val_acc: 0.7907\n",
            "Epoch 354/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0162 - acc: 0.9822 - val_loss: 0.1864 - val_acc: 0.7907\n",
            "Epoch 355/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0158 - acc: 0.9822 - val_loss: 0.1881 - val_acc: 0.7907\n",
            "Epoch 356/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0149 - acc: 0.9822 - val_loss: 0.1811 - val_acc: 0.7907\n",
            "Epoch 357/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0195 - acc: 0.9763 - val_loss: 0.1863 - val_acc: 0.7907\n",
            "Epoch 358/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0202 - acc: 0.9704 - val_loss: 0.1638 - val_acc: 0.8140\n",
            "Epoch 359/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9645 - val_loss: 0.2041 - val_acc: 0.7442\n",
            "Epoch 360/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0306 - acc: 0.9645 - val_loss: 0.2188 - val_acc: 0.7209\n",
            "Epoch 361/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0481 - acc: 0.9408 - val_loss: 0.2167 - val_acc: 0.7442\n",
            "Epoch 362/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0413 - acc: 0.9408 - val_loss: 0.1971 - val_acc: 0.7907\n",
            "Epoch 363/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0256 - acc: 0.9645 - val_loss: 0.2158 - val_acc: 0.7674\n",
            "Epoch 364/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0315 - acc: 0.9586 - val_loss: 0.2055 - val_acc: 0.7442\n",
            "Epoch 365/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0252 - acc: 0.9704 - val_loss: 0.1869 - val_acc: 0.7907\n",
            "Epoch 366/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0162 - acc: 0.9822 - val_loss: 0.1821 - val_acc: 0.7674\n",
            "Epoch 367/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0207 - acc: 0.9763 - val_loss: 0.1733 - val_acc: 0.7907\n",
            "Epoch 368/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0152 - acc: 0.9822 - val_loss: 0.1976 - val_acc: 0.7442\n",
            "Epoch 369/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0163 - acc: 0.9763 - val_loss: 0.1883 - val_acc: 0.7674\n",
            "Epoch 370/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0099 - acc: 0.9882 - val_loss: 0.1880 - val_acc: 0.7674\n",
            "Epoch 371/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0103 - acc: 0.9882 - val_loss: 0.1827 - val_acc: 0.7907\n",
            "Epoch 372/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0098 - acc: 0.9882 - val_loss: 0.1816 - val_acc: 0.7907\n",
            "Epoch 373/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0093 - acc: 0.9882 - val_loss: 0.1813 - val_acc: 0.7907\n",
            "Epoch 374/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0094 - acc: 0.9882 - val_loss: 0.1825 - val_acc: 0.7907\n",
            "Epoch 375/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0093 - acc: 0.9882 - val_loss: 0.1821 - val_acc: 0.7907\n",
            "Epoch 376/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0093 - acc: 0.9882 - val_loss: 0.1830 - val_acc: 0.7907\n",
            "Epoch 377/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0089 - acc: 0.9882 - val_loss: 0.1836 - val_acc: 0.7907\n",
            "Epoch 378/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0090 - acc: 0.9882 - val_loss: 0.1844 - val_acc: 0.7907\n",
            "Epoch 379/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0090 - acc: 0.9882 - val_loss: 0.1827 - val_acc: 0.7907\n",
            "Epoch 380/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0089 - acc: 0.9882 - val_loss: 0.1819 - val_acc: 0.7907\n",
            "Epoch 381/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0087 - acc: 0.9882 - val_loss: 0.1812 - val_acc: 0.7907\n",
            "Epoch 382/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0092 - acc: 0.9882 - val_loss: 0.1820 - val_acc: 0.7907\n",
            "Epoch 383/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0085 - acc: 0.9882 - val_loss: 0.1806 - val_acc: 0.7907\n",
            "Epoch 384/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0086 - acc: 0.9882 - val_loss: 0.1808 - val_acc: 0.7907\n",
            "Epoch 385/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0087 - acc: 0.9882 - val_loss: 0.1816 - val_acc: 0.7907\n",
            "Epoch 386/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0085 - acc: 0.9882 - val_loss: 0.1812 - val_acc: 0.7907\n",
            "Epoch 387/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - acc: 0.9882 - val_loss: 0.1799 - val_acc: 0.7907\n",
            "Epoch 388/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0086 - acc: 0.9882 - val_loss: 0.1790 - val_acc: 0.7907\n",
            "Epoch 389/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0083 - acc: 0.9822 - val_loss: 0.1799 - val_acc: 0.7907\n",
            "Epoch 390/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0090 - acc: 0.9882 - val_loss: 0.1815 - val_acc: 0.7907\n",
            "Epoch 391/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - acc: 0.9882 - val_loss: 0.1783 - val_acc: 0.7907\n",
            "Epoch 392/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0083 - acc: 0.9882 - val_loss: 0.1789 - val_acc: 0.7907\n",
            "Epoch 393/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0086 - acc: 0.9822 - val_loss: 0.1785 - val_acc: 0.7907\n",
            "Epoch 394/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - acc: 0.9822 - val_loss: 0.1790 - val_acc: 0.7907\n",
            "Epoch 395/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0085 - acc: 0.9882 - val_loss: 0.1811 - val_acc: 0.7907\n",
            "Epoch 396/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0084 - acc: 0.9882 - val_loss: 0.1776 - val_acc: 0.7907\n",
            "Epoch 397/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0081 - acc: 0.9822 - val_loss: 0.1773 - val_acc: 0.7907\n",
            "Epoch 398/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0082 - acc: 0.9822 - val_loss: 0.1782 - val_acc: 0.7907\n",
            "Epoch 399/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0081 - acc: 0.9882 - val_loss: 0.1778 - val_acc: 0.7907\n",
            "Epoch 400/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0081 - acc: 0.9822 - val_loss: 0.1786 - val_acc: 0.7907\n",
            "Epoch 401/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0080 - acc: 0.9822 - val_loss: 0.1793 - val_acc: 0.7907\n",
            "Epoch 402/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0082 - acc: 0.9822 - val_loss: 0.1794 - val_acc: 0.7907\n",
            "Epoch 403/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0083 - acc: 0.9882 - val_loss: 0.1801 - val_acc: 0.7907\n",
            "Epoch 404/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0082 - acc: 0.9882 - val_loss: 0.1790 - val_acc: 0.7907\n",
            "Epoch 405/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0080 - acc: 0.9882 - val_loss: 0.1780 - val_acc: 0.7907\n",
            "Epoch 406/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0080 - acc: 0.9882 - val_loss: 0.1782 - val_acc: 0.7907\n",
            "Epoch 407/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0079 - acc: 0.9882 - val_loss: 0.1785 - val_acc: 0.7907\n",
            "Epoch 408/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0078 - acc: 0.9882 - val_loss: 0.1788 - val_acc: 0.7907\n",
            "Epoch 409/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0081 - acc: 0.9822 - val_loss: 0.1794 - val_acc: 0.7907\n",
            "Epoch 410/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0081 - acc: 0.9822 - val_loss: 0.1777 - val_acc: 0.7907\n",
            "Epoch 411/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0078 - acc: 0.9822 - val_loss: 0.1774 - val_acc: 0.7907\n",
            "Epoch 412/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0079 - acc: 0.9822 - val_loss: 0.1779 - val_acc: 0.7907\n",
            "Epoch 413/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0083 - acc: 0.9822 - val_loss: 0.1773 - val_acc: 0.7907\n",
            "Epoch 414/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0084 - acc: 0.9822 - val_loss: 0.1793 - val_acc: 0.7907\n",
            "Epoch 415/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0078 - acc: 0.9822 - val_loss: 0.1786 - val_acc: 0.7907\n",
            "Epoch 416/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0080 - acc: 0.9822 - val_loss: 0.1789 - val_acc: 0.7907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sYpy54d2t4H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "4d7840d7-b207-416c-848d-887391752f41"
      },
      "source": [
        "### 12. What does the plot generated by this code represent?\n",
        "\n",
        "plt.plot(output.history['acc'])\n",
        "plt.plot(output.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "#plt.savefig('Accuracy.png',dpi=100) #to save the image\n",
        "plt.show()\n",
        "\n",
        "# The plot generated by this code represents the model's accuracy over epochs during training and validation."
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIrcCZ8P2t4N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "b612754d-df00-421b-d375-acac1498e1fc"
      },
      "source": [
        "### 13. Plot code for the model loss. You can refer to the plot code for model accuracy above.\n",
        "plt.plot(output.history['loss'])\n",
        "plt.plot(output.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "#plt.savefig('loss.png',dpi=100) #to save the image\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KTWzuJM12t4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcf955b-c193-4ef2-b849-55e23ad853c8"
      },
      "source": [
        "### 14. What is the purpose of evaluating the model on the test dataset?\n",
        "\n",
        "#model.load_weights(model_loc+\"heart_disease_best_model.hdf5\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[0], scores[0]))\n",
        "print(\"loss:\", round(scores[0],2))\n",
        "\n",
        "# The purpose of evaluating the model on the test dataset is to assess\n",
        "# its performance and generalization ability on unseen data that was not\n",
        "# used during training or validation."
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1873 - acc: 0.7912\n",
            "\n",
            "acc: 79.12%\n",
            "loss: 0.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNYy0CRt2t4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95601676-4466-4b73-d18f-9aa73acb48fd"
      },
      "source": [
        "#Display detailed prediction\n",
        "pred = model.predict(x_test)\n",
        "y = np.round(pred).astype(\"int16\")\n",
        "idx = 0\n",
        "ps = 0\n",
        "fl = 0\n",
        "for x in pred:\n",
        "    if y_test[idx]==y[idx]:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\"Result: \\033[92mPass\")\n",
        "        ps = ps+1\n",
        "    else:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\" Result: \\033[91mFail\")\n",
        "        fl = fl+1\n",
        "    idx = idx + 1\n",
        "print(\"\\033[30mRight Prediction :\",ps, \"Wrong Prediction :\",fl)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n",
            "\u001b[30mNo: 1 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 2 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 3 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 4 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 5 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 6 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 7 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 8 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 9 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 10 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 11 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 12 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 13 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 14 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 15 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 16 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 17 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 18 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 19 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 20 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 21 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 22 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 23 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 24 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 25 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 26 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 27 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 28 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 29 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 30 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 31 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 32 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 33 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 34 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 35 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 36 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 37 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 38 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 39 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 40 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 41 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 42 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 43 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 44 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 45 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 46 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 47 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 48 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 49 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 50 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 51 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 52 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 53 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 54 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 55 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 56 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 57 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 58 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 59 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 60 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 61 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 62 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 63 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 64 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 65 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 66 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 67 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 68 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 69 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 70 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 71 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 72 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 73 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 74 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 75 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 76 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 77 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 78 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 79 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 80 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 81 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 82 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 83 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 84 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 85 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 86 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 87 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 88 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 89 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 90 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 91 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mRight Prediction : 72 Wrong Prediction : 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHQBXNX5aYcn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "bc2ec84b-149a-423c-d1ea-fecb5927e24e"
      },
      "source": [
        "### 15. What is Confusion Matrix and why you need it? Explain TP, FP, FN, TN.\n",
        "### 16. Explain the classification report produce.\n",
        "\n",
        "y_pred = y\n",
        "y_true = y_test\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "#cm = confusion_matrix(y_true, y_pred, labels=labels.astype('int'))\n",
        "f, ax=plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(cm,annot=True,linewidths=1.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()\n",
        "print()\n",
        "print(classification_report(y_true, y_pred, labels=[0,1]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.71      0.75        41\n",
            "           1       0.78      0.86      0.82        50\n",
            "\n",
            "    accuracy                           0.79        91\n",
            "   macro avg       0.79      0.78      0.79        91\n",
            "weighted avg       0.79      0.79      0.79        91\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Confusion Matrix is a performance measurement technique for machine learning classification algorithms. It is a square matrix where the rows represent the actual classes, and the columns represent the predicted classes. Each cell in the matrix represents the count of instances where the actual class matches the predicted class."
      ],
      "metadata": {
        "id": "AOkdTv02v56Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "True Positive (TP): Instances where the model correctly predicts the positive class.\n",
        "\n",
        "False Positive (FP): Instances where the model incorrectly predicts the positive class when the actual class is negative. Also known as Type I error.\n",
        "\n",
        "False Negative (FN): Instances where the model incorrectly predicts the negative class when the actual class is positive. Also known as Type II error.\n",
        "\n",
        "True Negative (TN): Instances where the model correctly predicts the negative class."
      ],
      "metadata": {
        "id": "EbmfuJ_8wAUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For class 0:\n",
        "\n",
        "The Precision is 0.81, which means that 81% of instances predicted as class 0 are actually class 0.\n",
        "\n",
        "The Recall is 0.71, indicating that the model correctly identifies 71% of all actual class 0 instances.\n",
        "\n",
        "F1-score is 0.75, which is the harmonic mean of precision and recall for class 0.\n",
        "\n",
        "Support: 41, meaning that there are 41 instances of class 0 in the dataset.\n",
        "\n",
        "<hr>\n",
        "\n",
        "For class 1:\n",
        "\n",
        "Precision is 0.78, which means that 78% of instances predicted as class 1 are actually class 1.\n",
        "\n",
        "Recall is 0.86, indicating that the model correctly identifies 86% of all actual class 1 instances.\n",
        "\n",
        "F1-score is 0.82, which is the harmonic mean of precision and recall for class 1.\n",
        "\n",
        "Support is 50, meaning that there are 50 instances of class 1 in the dataset.\n",
        "\n",
        "Accuracy is 0.79, indicating that the overall correctness of the model's predictions is 79%.\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "Macro average is 0.79, which is the average of precision, recall, and F1-score calculated independently for each class.\n",
        "\n",
        "Weighted average: 0.79, which is the average of precision, recall, and F1-score weighted by the support for each class."
      ],
      "metadata": {
        "id": "EX8mcz_rwPTr"
      }
    }
  ]
}