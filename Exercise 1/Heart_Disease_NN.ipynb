{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1q_qKIV2t2u"
      },
      "source": [
        "#Import all library needed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,BatchNormalization, Dropout\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "#confusion matrix visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 1. Link notebook with google drive and access data from your personal Gdrive\n",
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "### 2.Set the data path for dataset and model location (ex: model_loc = \"/content/gdrive/My Drive/Dataset/\")\n",
        "dataset_dir = \"/content/gdrive/My Drive/BIOINFORMATICSII/\"\n",
        "model_loc = \"/content/gdrive/My Drive/BIOINFORMATICSII/\"\n",
        "\n",
        "print(os.listdir(dataset_dir))\n",
        "data = pd.read_csv(dataset_dir+'heart.csv')"
      ],
      "metadata": {
        "id": "WazdlOZefP88",
        "outputId": "348c8b87-de14-4fc1-b2b5-0d03a3219eaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "['Heart_Disease_NN.ipynb', 'heart.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZADep6q2t3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1134933c-1c96-4c22-9468-bafc28b512af"
      },
      "source": [
        "### 3. Insert Exploratory data analysis (EDA) steps to analyze and investigate datasets.\n",
        "print(data.info())\n",
        "print(data.head(10))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trestbps  303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    int64  \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n",
            "None\n",
            "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
            "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
            "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
            "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
            "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
            "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
            "5   57    1   0       140   192    0        1      148      0      0.4      1   \n",
            "6   56    0   1       140   294    0        0      153      0      1.3      1   \n",
            "7   44    1   1       120   263    0        1      173      0      0.0      2   \n",
            "8   52    1   2       172   199    1        1      162      0      0.5      2   \n",
            "9   57    1   2       150   168    0        1      174      0      1.6      2   \n",
            "\n",
            "   ca  thal  target  \n",
            "0   0     1       1  \n",
            "1   0     2       1  \n",
            "2   0     2       1  \n",
            "3   0     2       1  \n",
            "4   0     2       1  \n",
            "5   0     1       1  \n",
            "6   0     2       1  \n",
            "7   0     3       1  \n",
            "8   0     3       1  \n",
            "9   0     2       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ylkru32t27"
      },
      "source": [
        "### 4. What is the purpose of the code that sets a list of categorical variables\n",
        "### in a dataset and then casts those variables to the object data type using the astype() function?\n",
        "\n",
        "catagorialList = ['sex','cp','fbs','restecg','exang','ca','thal']\n",
        "for item in catagorialList:\n",
        "    data[item] = data[item].astype('object') #casting to object",
        "\n###is to ensures that the specified columns are treated as categorical data"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNbqP4z32t3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87018d4d-0f0d-457c-cf22-b64c8cafb2b8"
      },
      "source": [
        " ### 5. Create more data by categorical variable into indicator variables using 'get_dummies' function\n",
        "\n",
        "data = pd.get_dummies(data, drop_first=True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-44-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-44-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-44-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-44-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-44-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-44-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhlOEgqg2t3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c2f8b87-9d9c-46a1-c867-e9fa7378cd21"
      },
      "source": [
        "### 6. Explain line 3,4 and 5 and print the shape of x and y\n",
        "\n",
        "y = data['target'].values # take target of the value\n",
        "y = y.reshape(y.shape[0],1) # reshape y array into 1 dimension\n",
        "x = data.drop(['target'],axis=1) #drop the  'target' in the x data\n",
        "##\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(303, 21)\n",
            "(303, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEGdOBJu2t3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54026128-ee59-4d07-e92f-cc3f00c51038"
      },
      "source": [
        "### 7. Create a simple dataset and demonstrate the normalization code on the simple dataset\n",
        "data = pd.DataFrame({'A':[10,20,30], 'B':[100,200,300], 'C':[1000, 2000, 3000]})\n",
        "print(\"Original Dataset:\")\n",
        "print(data)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset:\n",
            "    A    B     C\n",
            "0  10  100  1000\n",
            "1  20  200  2000\n",
            "2  30  300  3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 8. Describe the heart dataset after implementing the min max normalization\n",
        "#Normalize data (range 0 - 1)\n",
        "minx = np.min(x)\n",
        "maxx = np.max(x)\n",
        "x = (x - minx) / (maxx - minx)\n",
        "x.head()\n"
      ],
      "metadata": {
        "id": "asoFBQaumuKA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "abac6753-7d6a-497a-bc50-d27908556a38"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age  trestbps      chol   thalach   oldpeak  slope  sex_1  cp_1  cp_2  \\\n",
              "0  0.708333  0.481132  0.244292  0.603053  0.370968    0.0    1.0   0.0   0.0   \n",
              "1  0.166667  0.339623  0.283105  0.885496  0.564516    0.0    1.0   0.0   1.0   \n",
              "2  0.250000  0.339623  0.178082  0.770992  0.225806    1.0    0.0   1.0   0.0   \n",
              "3  0.562500  0.245283  0.251142  0.816794  0.129032    1.0    1.0   1.0   0.0   \n",
              "4  0.583333  0.245283  0.520548  0.702290  0.096774    1.0    0.0   0.0   0.0   \n",
              "\n",
              "   cp_3  ...  restecg_1  restecg_2  exang_1  ca_1  ca_2  ca_3  ca_4  thal_1  \\\n",
              "0   1.0  ...        0.0        0.0      0.0   0.0   0.0   0.0   0.0     1.0   \n",
              "1   0.0  ...        1.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "2   0.0  ...        0.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "3   0.0  ...        1.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "4   0.0  ...        1.0        0.0      1.0   0.0   0.0   0.0   0.0     0.0   \n",
              "\n",
              "   thal_2  thal_3  \n",
              "0     0.0     0.0  \n",
              "1     1.0     0.0  \n",
              "2     1.0     0.0  \n",
              "3     1.0     0.0  \n",
              "4     1.0     0.0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6108371-5145-4883-809a-d0b87ada83bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>cp_3</th>\n",
              "      <th>...</th>\n",
              "      <th>restecg_1</th>\n",
              "      <th>restecg_2</th>\n",
              "      <th>exang_1</th>\n",
              "      <th>ca_1</th>\n",
              "      <th>ca_2</th>\n",
              "      <th>ca_3</th>\n",
              "      <th>ca_4</th>\n",
              "      <th>thal_1</th>\n",
              "      <th>thal_2</th>\n",
              "      <th>thal_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.481132</td>\n",
              "      <td>0.244292</td>\n",
              "      <td>0.603053</td>\n",
              "      <td>0.370968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.283105</td>\n",
              "      <td>0.885496</td>\n",
              "      <td>0.564516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.178082</td>\n",
              "      <td>0.770992</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.251142</td>\n",
              "      <td>0.816794</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.702290</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6108371-5145-4883-809a-d0b87ada83bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6108371-5145-4883-809a-d0b87ada83bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6108371-5145-4883-809a-d0b87ada83bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-56095767-efd7-42b9-9cd4-807e04524442\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-56095767-efd7-42b9-9cd4-807e04524442')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-56095767-efd7-42b9-9cd4-807e04524442 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying min-max normalization to the heart dataset, all values are scaled to a range between 0 and 1. This ensures uniformity in the scale of features, facilitating better learning for machine learning algorithms."
      ],
      "metadata": {
        "id": "HG0TYowg4GZb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvykedw82t3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5571c11d-3fdc-42b5-f7ad-c099092f13f0"
      },
      "source": [
        "### 9. Modify the code to split the dataset into train and test (train 70%, val 20% and test 10%).\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "# re-create train and validation set\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "# train 70%, validation 20%, test 10%\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(169, 21)\n",
            "(43, 21)\n",
            "(91, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pwz5A_j2t30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee74c6d-dda4-41bf-9dc0-577dccf44044"
      },
      "source": [
        "### 10. What is the purpose of each layer in the neural network created using the Sequential() function with 64, 32, and 1 neurons,\n",
        "### respectively, and softmax and sigmoid activation functions?\n",
        "\n",
        "model = Sequential() #Allow us to create model layer by layer\n",
        "model.add(Dense(64, input_dim=21, activation='softmax')) #Softmax turn number data into probabilities which sum to 1\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.add(Dense(1, activation='sigmoid')) # produce probability value (number between 0 or 1)\n",
        "model.summary()\n",
        "\n",
        "###The first two layers are hidden layers with softmax activation, which are used for feature extraction and learning complex patterns in the data.\n",
        "###The last layer is the output layer with sigmoid activation, which produces the final prediction probabilities for binary classification problems."
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 64)                1408      \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3521 (13.75 KB)\n",
            "Trainable params: 3521 (13.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0pM4z_OQfNi"
      },
      "source": [
        "### 11. This code compiles a neural network model with a mean squared error loss function, the Adam optimizer with a learning rate of 0.01,\n",
        "### and accuracy as a performance metric. What does each of these components mean, and how do they affect the model training and performance?\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999,epsilon=1e-07, amsgrad=False,name='Adam'),\n",
        "              metrics=['acc'])\n",
        "# The mean squared error loss function quantifies how well the model's predictions match the actual target values during training.\n",
        "# The choice of loss function affects how the model learns from the data and directly impacts the optimization process.\n",
        "\n",
        "# The Adam optimizer determines how the model's weights are updated during training to minimize the loss function.\n",
        "# Learning rate (0.01 in this case) controls the step size taken during the optimization process. A larger learning rate may result\n",
        "# in faster convergence but can overshoot the minimum, while a smaller learning rate may take longer to converge but may converge to a more precise minimum.\n",
        "# It help determines how the model's weights are updated during training. Adam optimizer adapts the learning rate for each parameter,\n",
        "# resulting in faster convergence and better performance compared to traditional gradient descent algorithms.\n",
        "\n",
        "# The performance metrics are used to evaluate the performance of the model during training and testing.\n",
        "# It provides insight into how well the model is performing during training and evaluation."
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unxSIBnZ2t36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a4dc2f0-64c2-46f8-9e99-ecb26f0877f6"
      },
      "source": [
        "# start the model training\n",
        "output = []\n",
        "early = EarlyStopping(monitor='val_acc', patience=400, mode='auto')\n",
        "checkpoint = ModelCheckpoint(model_loc+\"heart_disease_best_model.hdf5\", monitor='val_acc', verbose=0, save_best_only=True, mode='auto', save_freq='epoch')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.01, patience=100, verbose=1, mode='auto', min_lr=0.001)\n",
        "callbacks_list = [early]\n",
        "\n",
        "output = model.fit(x_train, y_train,validation_data=(x_val,y_val), epochs=1000, batch_size=16, verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "11/11 [==============================] - 1s 23ms/step - loss: 0.2494 - acc: 0.5207 - val_loss: 0.2509 - val_acc: 0.4884\n",
            "Epoch 2/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2473 - acc: 0.5562 - val_loss: 0.2509 - val_acc: 0.4884\n",
            "Epoch 3/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2454 - acc: 0.5562 - val_loss: 0.2496 - val_acc: 0.4884\n",
            "Epoch 4/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2422 - acc: 0.5562 - val_loss: 0.2452 - val_acc: 0.4884\n",
            "Epoch 5/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2370 - acc: 0.5562 - val_loss: 0.2390 - val_acc: 0.4884\n",
            "Epoch 6/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2284 - acc: 0.5621 - val_loss: 0.2264 - val_acc: 0.6744\n",
            "Epoch 7/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2157 - acc: 0.7337 - val_loss: 0.2131 - val_acc: 0.7907\n",
            "Epoch 8/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2011 - acc: 0.8402 - val_loss: 0.1960 - val_acc: 0.8605\n",
            "Epoch 9/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1852 - acc: 0.8521 - val_loss: 0.1795 - val_acc: 0.8605\n",
            "Epoch 10/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1702 - acc: 0.8462 - val_loss: 0.1657 - val_acc: 0.8605\n",
            "Epoch 11/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1559 - acc: 0.8521 - val_loss: 0.1535 - val_acc: 0.8605\n",
            "Epoch 12/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1450 - acc: 0.8462 - val_loss: 0.1441 - val_acc: 0.8605\n",
            "Epoch 13/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1357 - acc: 0.8639 - val_loss: 0.1417 - val_acc: 0.8605\n",
            "Epoch 14/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1282 - acc: 0.8580 - val_loss: 0.1358 - val_acc: 0.8605\n",
            "Epoch 15/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1226 - acc: 0.8580 - val_loss: 0.1352 - val_acc: 0.8372\n",
            "Epoch 16/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1162 - acc: 0.8639 - val_loss: 0.1329 - val_acc: 0.8372\n",
            "Epoch 17/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1109 - acc: 0.8698 - val_loss: 0.1327 - val_acc: 0.8372\n",
            "Epoch 18/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1071 - acc: 0.8698 - val_loss: 0.1335 - val_acc: 0.8372\n",
            "Epoch 19/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1041 - acc: 0.8698 - val_loss: 0.1350 - val_acc: 0.8605\n",
            "Epoch 20/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1018 - acc: 0.8698 - val_loss: 0.1369 - val_acc: 0.8605\n",
            "Epoch 21/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0988 - acc: 0.8817 - val_loss: 0.1375 - val_acc: 0.8605\n",
            "Epoch 22/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0954 - acc: 0.8876 - val_loss: 0.1366 - val_acc: 0.8605\n",
            "Epoch 23/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0946 - acc: 0.8994 - val_loss: 0.1378 - val_acc: 0.8372\n",
            "Epoch 24/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0876 - acc: 0.9053 - val_loss: 0.1401 - val_acc: 0.8372\n",
            "Epoch 25/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0857 - acc: 0.8994 - val_loss: 0.1417 - val_acc: 0.8372\n",
            "Epoch 26/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0815 - acc: 0.9053 - val_loss: 0.1421 - val_acc: 0.8140\n",
            "Epoch 27/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0789 - acc: 0.9172 - val_loss: 0.1488 - val_acc: 0.8140\n",
            "Epoch 28/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0772 - acc: 0.9172 - val_loss: 0.1516 - val_acc: 0.8372\n",
            "Epoch 29/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0744 - acc: 0.9172 - val_loss: 0.1613 - val_acc: 0.8140\n",
            "Epoch 30/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0754 - acc: 0.9112 - val_loss: 0.1588 - val_acc: 0.8140\n",
            "Epoch 31/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0732 - acc: 0.9172 - val_loss: 0.1598 - val_acc: 0.7907\n",
            "Epoch 32/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0700 - acc: 0.9231 - val_loss: 0.1580 - val_acc: 0.8140\n",
            "Epoch 33/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0664 - acc: 0.9290 - val_loss: 0.1589 - val_acc: 0.7907\n",
            "Epoch 34/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0671 - acc: 0.9231 - val_loss: 0.1600 - val_acc: 0.7907\n",
            "Epoch 35/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0626 - acc: 0.9349 - val_loss: 0.1615 - val_acc: 0.8140\n",
            "Epoch 36/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0605 - acc: 0.9349 - val_loss: 0.1655 - val_acc: 0.7907\n",
            "Epoch 37/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0591 - acc: 0.9290 - val_loss: 0.1600 - val_acc: 0.8140\n",
            "Epoch 38/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0575 - acc: 0.9349 - val_loss: 0.1535 - val_acc: 0.8372\n",
            "Epoch 39/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0555 - acc: 0.9408 - val_loss: 0.1627 - val_acc: 0.7674\n",
            "Epoch 40/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0539 - acc: 0.9408 - val_loss: 0.1584 - val_acc: 0.8140\n",
            "Epoch 41/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0520 - acc: 0.9527 - val_loss: 0.1677 - val_acc: 0.7907\n",
            "Epoch 42/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0488 - acc: 0.9586 - val_loss: 0.1697 - val_acc: 0.7907\n",
            "Epoch 43/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0470 - acc: 0.9586 - val_loss: 0.1704 - val_acc: 0.7907\n",
            "Epoch 44/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0453 - acc: 0.9586 - val_loss: 0.1704 - val_acc: 0.7907\n",
            "Epoch 45/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0444 - acc: 0.9586 - val_loss: 0.1711 - val_acc: 0.7907\n",
            "Epoch 46/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0437 - acc: 0.9586 - val_loss: 0.1733 - val_acc: 0.7907\n",
            "Epoch 47/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0429 - acc: 0.9586 - val_loss: 0.1805 - val_acc: 0.7674\n",
            "Epoch 48/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0432 - acc: 0.9527 - val_loss: 0.1765 - val_acc: 0.7674\n",
            "Epoch 49/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0411 - acc: 0.9645 - val_loss: 0.1806 - val_acc: 0.7674\n",
            "Epoch 50/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0421 - acc: 0.9586 - val_loss: 0.1714 - val_acc: 0.7907\n",
            "Epoch 51/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0420 - acc: 0.9586 - val_loss: 0.1735 - val_acc: 0.7907\n",
            "Epoch 52/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0414 - acc: 0.9586 - val_loss: 0.1837 - val_acc: 0.7674\n",
            "Epoch 53/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0401 - acc: 0.9586 - val_loss: 0.1727 - val_acc: 0.8140\n",
            "Epoch 54/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0411 - acc: 0.9586 - val_loss: 0.1778 - val_acc: 0.7674\n",
            "Epoch 55/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0394 - acc: 0.9586 - val_loss: 0.1831 - val_acc: 0.7674\n",
            "Epoch 56/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0392 - acc: 0.9586 - val_loss: 0.1816 - val_acc: 0.7674\n",
            "Epoch 57/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0393 - acc: 0.9586 - val_loss: 0.1803 - val_acc: 0.7674\n",
            "Epoch 58/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0386 - acc: 0.9586 - val_loss: 0.1786 - val_acc: 0.7674\n",
            "Epoch 59/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0373 - acc: 0.9645 - val_loss: 0.1840 - val_acc: 0.7674\n",
            "Epoch 60/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0379 - acc: 0.9586 - val_loss: 0.1924 - val_acc: 0.7674\n",
            "Epoch 61/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0349 - acc: 0.9645 - val_loss: 0.1747 - val_acc: 0.7907\n",
            "Epoch 62/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0418 - acc: 0.9527 - val_loss: 0.1961 - val_acc: 0.7674\n",
            "Epoch 63/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0401 - acc: 0.9586 - val_loss: 0.1858 - val_acc: 0.7674\n",
            "Epoch 64/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0376 - acc: 0.9645 - val_loss: 0.2062 - val_acc: 0.7674\n",
            "Epoch 65/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0370 - acc: 0.9645 - val_loss: 0.1672 - val_acc: 0.8140\n",
            "Epoch 66/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0318 - acc: 0.9704 - val_loss: 0.2071 - val_acc: 0.7442\n",
            "Epoch 67/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0311 - acc: 0.9763 - val_loss: 0.1883 - val_acc: 0.7907\n",
            "Epoch 68/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0307 - acc: 0.9704 - val_loss: 0.1940 - val_acc: 0.7907\n",
            "Epoch 69/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0309 - acc: 0.9704 - val_loss: 0.1798 - val_acc: 0.7907\n",
            "Epoch 70/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0297 - acc: 0.9704 - val_loss: 0.1794 - val_acc: 0.7907\n",
            "Epoch 71/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0282 - acc: 0.9704 - val_loss: 0.1824 - val_acc: 0.7907\n",
            "Epoch 72/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0287 - acc: 0.9704 - val_loss: 0.1816 - val_acc: 0.7907\n",
            "Epoch 73/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0297 - acc: 0.9645 - val_loss: 0.1809 - val_acc: 0.7907\n",
            "Epoch 74/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0288 - acc: 0.9704 - val_loss: 0.1847 - val_acc: 0.7907\n",
            "Epoch 75/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0275 - acc: 0.9763 - val_loss: 0.1798 - val_acc: 0.7907\n",
            "Epoch 76/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0272 - acc: 0.9763 - val_loss: 0.1830 - val_acc: 0.7907\n",
            "Epoch 77/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0271 - acc: 0.9704 - val_loss: 0.1806 - val_acc: 0.7907\n",
            "Epoch 78/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0294 - acc: 0.9704 - val_loss: 0.1818 - val_acc: 0.7907\n",
            "Epoch 79/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0342 - acc: 0.9586 - val_loss: 0.1803 - val_acc: 0.8140\n",
            "Epoch 80/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0328 - acc: 0.9586 - val_loss: 0.1858 - val_acc: 0.7907\n",
            "Epoch 81/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0279 - acc: 0.9704 - val_loss: 0.1784 - val_acc: 0.8140\n",
            "Epoch 82/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0280 - acc: 0.9704 - val_loss: 0.1773 - val_acc: 0.8140\n",
            "Epoch 83/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0266 - acc: 0.9763 - val_loss: 0.1775 - val_acc: 0.8140\n",
            "Epoch 84/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0262 - acc: 0.9763 - val_loss: 0.1788 - val_acc: 0.7907\n",
            "Epoch 85/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0270 - acc: 0.9704 - val_loss: 0.1759 - val_acc: 0.8140\n",
            "Epoch 86/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0261 - acc: 0.9763 - val_loss: 0.1778 - val_acc: 0.8140\n",
            "Epoch 87/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0259 - acc: 0.9763 - val_loss: 0.1782 - val_acc: 0.8140\n",
            "Epoch 88/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0266 - acc: 0.9704 - val_loss: 0.1797 - val_acc: 0.7907\n",
            "Epoch 89/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0258 - acc: 0.9763 - val_loss: 0.1804 - val_acc: 0.7907\n",
            "Epoch 90/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0257 - acc: 0.9763 - val_loss: 0.1784 - val_acc: 0.8140\n",
            "Epoch 91/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0261 - acc: 0.9763 - val_loss: 0.1783 - val_acc: 0.8140\n",
            "Epoch 92/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0257 - acc: 0.9763 - val_loss: 0.1794 - val_acc: 0.8140\n",
            "Epoch 93/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0272 - acc: 0.9704 - val_loss: 0.1788 - val_acc: 0.8140\n",
            "Epoch 94/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0254 - acc: 0.9763 - val_loss: 0.1779 - val_acc: 0.8140\n",
            "Epoch 95/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0258 - acc: 0.9763 - val_loss: 0.1786 - val_acc: 0.8140\n",
            "Epoch 96/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0255 - acc: 0.9763 - val_loss: 0.1791 - val_acc: 0.8140\n",
            "Epoch 97/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0253 - acc: 0.9763 - val_loss: 0.1793 - val_acc: 0.8140\n",
            "Epoch 98/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0253 - acc: 0.9763 - val_loss: 0.1790 - val_acc: 0.8140\n",
            "Epoch 99/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0253 - acc: 0.9763 - val_loss: 0.1791 - val_acc: 0.8140\n",
            "Epoch 100/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0252 - acc: 0.9763 - val_loss: 0.1790 - val_acc: 0.8140\n",
            "Epoch 101/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0254 - acc: 0.9763 - val_loss: 0.1798 - val_acc: 0.8140\n",
            "Epoch 102/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0254 - acc: 0.9763 - val_loss: 0.1803 - val_acc: 0.8140\n",
            "Epoch 103/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0249 - acc: 0.9763 - val_loss: 0.1783 - val_acc: 0.8140\n",
            "Epoch 104/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0246 - acc: 0.9763 - val_loss: 0.1782 - val_acc: 0.8140\n",
            "Epoch 105/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0250 - acc: 0.9763 - val_loss: 0.1801 - val_acc: 0.8140\n",
            "Epoch 106/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0245 - acc: 0.9763 - val_loss: 0.1817 - val_acc: 0.7907\n",
            "Epoch 107/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0250 - acc: 0.9763 - val_loss: 0.1786 - val_acc: 0.8140\n",
            "Epoch 108/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0247 - acc: 0.9763 - val_loss: 0.1788 - val_acc: 0.8140\n",
            "Epoch 109/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0246 - acc: 0.9763 - val_loss: 0.1798 - val_acc: 0.8140\n",
            "Epoch 110/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0245 - acc: 0.9763 - val_loss: 0.1803 - val_acc: 0.8140\n",
            "Epoch 111/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0244 - acc: 0.9763 - val_loss: 0.1801 - val_acc: 0.8140\n",
            "Epoch 112/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0245 - acc: 0.9763 - val_loss: 0.1809 - val_acc: 0.8140\n",
            "Epoch 113/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0244 - acc: 0.9763 - val_loss: 0.1813 - val_acc: 0.8140\n",
            "Epoch 114/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0245 - acc: 0.9763 - val_loss: 0.1803 - val_acc: 0.8140\n",
            "Epoch 115/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0243 - acc: 0.9763 - val_loss: 0.1789 - val_acc: 0.8140\n",
            "Epoch 116/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0243 - acc: 0.9763 - val_loss: 0.1797 - val_acc: 0.8140\n",
            "Epoch 117/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0245 - acc: 0.9763 - val_loss: 0.1803 - val_acc: 0.8140\n",
            "Epoch 118/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0242 - acc: 0.9763 - val_loss: 0.1797 - val_acc: 0.8140\n",
            "Epoch 119/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0244 - acc: 0.9763 - val_loss: 0.1811 - val_acc: 0.8140\n",
            "Epoch 120/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0247 - acc: 0.9763 - val_loss: 0.1811 - val_acc: 0.8140\n",
            "Epoch 121/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0252 - acc: 0.9763 - val_loss: 0.1805 - val_acc: 0.8140\n",
            "Epoch 122/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0243 - acc: 0.9763 - val_loss: 0.1826 - val_acc: 0.8140\n",
            "Epoch 123/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0243 - acc: 0.9763 - val_loss: 0.1804 - val_acc: 0.8140\n",
            "Epoch 124/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0244 - acc: 0.9763 - val_loss: 0.1828 - val_acc: 0.8140\n",
            "Epoch 125/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0246 - acc: 0.9763 - val_loss: 0.1834 - val_acc: 0.7907\n",
            "Epoch 126/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0247 - acc: 0.9763 - val_loss: 0.1801 - val_acc: 0.8140\n",
            "Epoch 127/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0253 - acc: 0.9704 - val_loss: 0.1811 - val_acc: 0.8140\n",
            "Epoch 128/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1793 - val_acc: 0.8140\n",
            "Epoch 129/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0247 - acc: 0.9763 - val_loss: 0.1812 - val_acc: 0.8140\n",
            "Epoch 130/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0242 - acc: 0.9763 - val_loss: 0.1831 - val_acc: 0.8140\n",
            "Epoch 131/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0239 - acc: 0.9763 - val_loss: 0.1816 - val_acc: 0.8140\n",
            "Epoch 132/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0239 - acc: 0.9763 - val_loss: 0.1810 - val_acc: 0.8140\n",
            "Epoch 133/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0239 - acc: 0.9763 - val_loss: 0.1814 - val_acc: 0.8140\n",
            "Epoch 134/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1820 - val_acc: 0.8140\n",
            "Epoch 135/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1813 - val_acc: 0.8140\n",
            "Epoch 136/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1813 - val_acc: 0.8140\n",
            "Epoch 137/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1827 - val_acc: 0.8140\n",
            "Epoch 138/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1824 - val_acc: 0.8140\n",
            "Epoch 139/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1814 - val_acc: 0.8140\n",
            "Epoch 140/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.8140\n",
            "Epoch 141/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1819 - val_acc: 0.8140\n",
            "Epoch 142/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1820 - val_acc: 0.8140\n",
            "Epoch 143/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1809 - val_acc: 0.8140\n",
            "Epoch 144/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1816 - val_acc: 0.8140\n",
            "Epoch 145/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1820 - val_acc: 0.8140\n",
            "Epoch 146/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0238 - acc: 0.9763 - val_loss: 0.1813 - val_acc: 0.8140\n",
            "Epoch 147/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1813 - val_acc: 0.8140\n",
            "Epoch 148/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1814 - val_acc: 0.8140\n",
            "Epoch 149/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1819 - val_acc: 0.8140\n",
            "Epoch 150/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1826 - val_acc: 0.8140\n",
            "Epoch 151/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1819 - val_acc: 0.8140\n",
            "Epoch 152/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1819 - val_acc: 0.8140\n",
            "Epoch 153/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1816 - val_acc: 0.8140\n",
            "Epoch 154/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1818 - val_acc: 0.8140\n",
            "Epoch 155/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1820 - val_acc: 0.8140\n",
            "Epoch 156/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1824 - val_acc: 0.8140\n",
            "Epoch 157/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.1818 - val_acc: 0.8140\n",
            "Epoch 158/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1823 - val_acc: 0.8140\n",
            "Epoch 159/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.8140\n",
            "Epoch 160/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1814 - val_acc: 0.8140\n",
            "Epoch 161/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1819 - val_acc: 0.8140\n",
            "Epoch 162/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1822 - val_acc: 0.8140\n",
            "Epoch 163/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1821 - val_acc: 0.8140\n",
            "Epoch 164/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1823 - val_acc: 0.8140\n",
            "Epoch 165/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1819 - val_acc: 0.8140\n",
            "Epoch 166/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1821 - val_acc: 0.8140\n",
            "Epoch 167/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1818 - val_acc: 0.8140\n",
            "Epoch 168/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1818 - val_acc: 0.8140\n",
            "Epoch 169/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1823 - val_acc: 0.8140\n",
            "Epoch 170/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1825 - val_acc: 0.8140\n",
            "Epoch 171/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1825 - val_acc: 0.8140\n",
            "Epoch 172/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1817 - val_acc: 0.8140\n",
            "Epoch 173/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1823 - val_acc: 0.8140\n",
            "Epoch 174/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1819 - val_acc: 0.8140\n",
            "Epoch 175/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1823 - val_acc: 0.8140\n",
            "Epoch 176/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1826 - val_acc: 0.8140\n",
            "Epoch 177/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1818 - val_acc: 0.8140\n",
            "Epoch 178/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1822 - val_acc: 0.8140\n",
            "Epoch 179/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1820 - val_acc: 0.8140\n",
            "Epoch 180/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.8140\n",
            "Epoch 181/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1817 - val_acc: 0.8140\n",
            "Epoch 182/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1826 - val_acc: 0.8140\n",
            "Epoch 183/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1821 - val_acc: 0.8140\n",
            "Epoch 184/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1823 - val_acc: 0.8140\n",
            "Epoch 185/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1822 - val_acc: 0.8140\n",
            "Epoch 186/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1821 - val_acc: 0.8140\n",
            "Epoch 187/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1818 - val_acc: 0.8140\n",
            "Epoch 188/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1823 - val_acc: 0.8140\n",
            "Epoch 189/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.8140\n",
            "Epoch 190/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.8140\n",
            "Epoch 191/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1820 - val_acc: 0.8140\n",
            "Epoch 192/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1814 - val_acc: 0.8140\n",
            "Epoch 193/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.8140\n",
            "Epoch 194/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.8140\n",
            "Epoch 195/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0235 - acc: 0.9763 - val_loss: 0.1816 - val_acc: 0.8140\n",
            "Epoch 196/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1821 - val_acc: 0.8140\n",
            "Epoch 197/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1819 - val_acc: 0.8140\n",
            "Epoch 198/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.8140\n",
            "Epoch 199/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1816 - val_acc: 0.8140\n",
            "Epoch 200/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1816 - val_acc: 0.8140\n",
            "Epoch 201/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1812 - val_acc: 0.8140\n",
            "Epoch 202/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1816 - val_acc: 0.8140\n",
            "Epoch 203/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1817 - val_acc: 0.8140\n",
            "Epoch 204/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.8140\n",
            "Epoch 205/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1817 - val_acc: 0.8140\n",
            "Epoch 206/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.8140\n",
            "Epoch 207/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1812 - val_acc: 0.8140\n",
            "Epoch 208/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1813 - val_acc: 0.8140\n",
            "Epoch 209/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1813 - val_acc: 0.8140\n",
            "Epoch 210/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1813 - val_acc: 0.8140\n",
            "Epoch 211/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1812 - val_acc: 0.8140\n",
            "Epoch 212/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1810 - val_acc: 0.8140\n",
            "Epoch 213/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1807 - val_acc: 0.8140\n",
            "Epoch 214/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1811 - val_acc: 0.8140\n",
            "Epoch 215/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1807 - val_acc: 0.8140\n",
            "Epoch 216/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1806 - val_acc: 0.8140\n",
            "Epoch 217/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1807 - val_acc: 0.8140\n",
            "Epoch 218/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1810 - val_acc: 0.8140\n",
            "Epoch 219/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1808 - val_acc: 0.8140\n",
            "Epoch 220/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1806 - val_acc: 0.8140\n",
            "Epoch 221/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1810 - val_acc: 0.8140\n",
            "Epoch 222/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1807 - val_acc: 0.8140\n",
            "Epoch 223/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1805 - val_acc: 0.8140\n",
            "Epoch 224/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1804 - val_acc: 0.8140\n",
            "Epoch 225/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1806 - val_acc: 0.8140\n",
            "Epoch 226/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1805 - val_acc: 0.8140\n",
            "Epoch 227/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1804 - val_acc: 0.8140\n",
            "Epoch 228/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1804 - val_acc: 0.8140\n",
            "Epoch 229/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1804 - val_acc: 0.8140\n",
            "Epoch 230/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1802 - val_acc: 0.8140\n",
            "Epoch 231/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1805 - val_acc: 0.8140\n",
            "Epoch 232/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1804 - val_acc: 0.8140\n",
            "Epoch 233/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1804 - val_acc: 0.8140\n",
            "Epoch 234/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1803 - val_acc: 0.8140\n",
            "Epoch 235/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1803 - val_acc: 0.8140\n",
            "Epoch 236/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1799 - val_acc: 0.8140\n",
            "Epoch 237/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1799 - val_acc: 0.8140\n",
            "Epoch 238/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1800 - val_acc: 0.8140\n",
            "Epoch 239/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1803 - val_acc: 0.8140\n",
            "Epoch 240/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1802 - val_acc: 0.8140\n",
            "Epoch 241/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1802 - val_acc: 0.8140\n",
            "Epoch 242/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1801 - val_acc: 0.8140\n",
            "Epoch 243/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1800 - val_acc: 0.8140\n",
            "Epoch 244/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1802 - val_acc: 0.8140\n",
            "Epoch 245/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1800 - val_acc: 0.8140\n",
            "Epoch 246/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1799 - val_acc: 0.8140\n",
            "Epoch 247/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1800 - val_acc: 0.8140\n",
            "Epoch 248/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1799 - val_acc: 0.8140\n",
            "Epoch 249/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1800 - val_acc: 0.8140\n",
            "Epoch 250/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1799 - val_acc: 0.8140\n",
            "Epoch 251/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1799 - val_acc: 0.8140\n",
            "Epoch 252/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1796 - val_acc: 0.8140\n",
            "Epoch 253/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1797 - val_acc: 0.8140\n",
            "Epoch 254/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1796 - val_acc: 0.8140\n",
            "Epoch 255/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1796 - val_acc: 0.8140\n",
            "Epoch 256/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1796 - val_acc: 0.8140\n",
            "Epoch 257/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1795 - val_acc: 0.8140\n",
            "Epoch 258/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1792 - val_acc: 0.8140\n",
            "Epoch 259/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1796 - val_acc: 0.8140\n",
            "Epoch 260/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1796 - val_acc: 0.8140\n",
            "Epoch 261/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1796 - val_acc: 0.8140\n",
            "Epoch 262/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1794 - val_acc: 0.8140\n",
            "Epoch 263/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1794 - val_acc: 0.8140\n",
            "Epoch 264/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1794 - val_acc: 0.8140\n",
            "Epoch 265/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1794 - val_acc: 0.8140\n",
            "Epoch 266/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1792 - val_acc: 0.8140\n",
            "Epoch 267/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1794 - val_acc: 0.8140\n",
            "Epoch 268/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1793 - val_acc: 0.8140\n",
            "Epoch 269/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1791 - val_acc: 0.8140\n",
            "Epoch 270/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1790 - val_acc: 0.8140\n",
            "Epoch 271/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1794 - val_acc: 0.8140\n",
            "Epoch 272/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1793 - val_acc: 0.8140\n",
            "Epoch 273/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1793 - val_acc: 0.8140\n",
            "Epoch 274/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1792 - val_acc: 0.8140\n",
            "Epoch 275/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1790 - val_acc: 0.8140\n",
            "Epoch 276/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1791 - val_acc: 0.8140\n",
            "Epoch 277/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1795 - val_acc: 0.8140\n",
            "Epoch 278/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1797 - val_acc: 0.8140\n",
            "Epoch 279/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1792 - val_acc: 0.8140\n",
            "Epoch 280/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1791 - val_acc: 0.8140\n",
            "Epoch 281/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1792 - val_acc: 0.8140\n",
            "Epoch 282/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1789 - val_acc: 0.8140\n",
            "Epoch 283/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1792 - val_acc: 0.8140\n",
            "Epoch 284/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1790 - val_acc: 0.8140\n",
            "Epoch 285/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1790 - val_acc: 0.8140\n",
            "Epoch 286/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1789 - val_acc: 0.8140\n",
            "Epoch 287/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1789 - val_acc: 0.8140\n",
            "Epoch 288/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1788 - val_acc: 0.8140\n",
            "Epoch 289/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1787 - val_acc: 0.8140\n",
            "Epoch 290/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1792 - val_acc: 0.8140\n",
            "Epoch 291/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1789 - val_acc: 0.8140\n",
            "Epoch 292/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1788 - val_acc: 0.8140\n",
            "Epoch 293/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1789 - val_acc: 0.8140\n",
            "Epoch 294/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1787 - val_acc: 0.8140\n",
            "Epoch 295/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1788 - val_acc: 0.8140\n",
            "Epoch 296/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1787 - val_acc: 0.8140\n",
            "Epoch 297/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1787 - val_acc: 0.8140\n",
            "Epoch 298/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1786 - val_acc: 0.8140\n",
            "Epoch 299/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1788 - val_acc: 0.8140\n",
            "Epoch 300/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1790 - val_acc: 0.8140\n",
            "Epoch 301/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1789 - val_acc: 0.8140\n",
            "Epoch 302/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1788 - val_acc: 0.8140\n",
            "Epoch 303/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1791 - val_acc: 0.8140\n",
            "Epoch 304/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1789 - val_acc: 0.8140\n",
            "Epoch 305/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1787 - val_acc: 0.8140\n",
            "Epoch 306/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1784 - val_acc: 0.8140\n",
            "Epoch 307/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1804 - val_acc: 0.8140\n",
            "Epoch 308/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1799 - val_acc: 0.8140\n",
            "Epoch 309/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1791 - val_acc: 0.8140\n",
            "Epoch 310/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1786 - val_acc: 0.8140\n",
            "Epoch 311/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1785 - val_acc: 0.8140\n",
            "Epoch 312/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1782 - val_acc: 0.8140\n",
            "Epoch 313/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1781 - val_acc: 0.8140\n",
            "Epoch 314/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1779 - val_acc: 0.8140\n",
            "Epoch 315/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1784 - val_acc: 0.8140\n",
            "Epoch 316/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0296 - acc: 0.9704 - val_loss: 0.1801 - val_acc: 0.8140\n",
            "Epoch 317/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0268 - acc: 0.9704 - val_loss: 0.2004 - val_acc: 0.7674\n",
            "Epoch 318/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0316 - acc: 0.9586 - val_loss: 0.1910 - val_acc: 0.7674\n",
            "Epoch 319/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0284 - acc: 0.9704 - val_loss: 0.1795 - val_acc: 0.8140\n",
            "Epoch 320/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0284 - acc: 0.9704 - val_loss: 0.1814 - val_acc: 0.8140\n",
            "Epoch 321/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0256 - acc: 0.9704 - val_loss: 0.1925 - val_acc: 0.7907\n",
            "Epoch 322/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0254 - acc: 0.9704 - val_loss: 0.1682 - val_acc: 0.8140\n",
            "Epoch 323/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0249 - acc: 0.9704 - val_loss: 0.1826 - val_acc: 0.8140\n",
            "Epoch 324/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0236 - acc: 0.9763 - val_loss: 0.1810 - val_acc: 0.8140\n",
            "Epoch 325/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.1794 - val_acc: 0.8140\n",
            "Epoch 326/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1796 - val_acc: 0.8140\n",
            "Epoch 327/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.1803 - val_acc: 0.8140\n",
            "Epoch 328/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1807 - val_acc: 0.8140\n",
            "Epoch 329/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1810 - val_acc: 0.8140\n",
            "Epoch 330/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1814 - val_acc: 0.8140\n",
            "Epoch 331/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1813 - val_acc: 0.8140\n",
            "Epoch 332/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1813 - val_acc: 0.8140\n",
            "Epoch 333/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.8140\n",
            "Epoch 334/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1814 - val_acc: 0.8140\n",
            "Epoch 335/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1817 - val_acc: 0.8140\n",
            "Epoch 336/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1817 - val_acc: 0.8140\n",
            "Epoch 337/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1814 - val_acc: 0.8140\n",
            "Epoch 338/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1816 - val_acc: 0.8140\n",
            "Epoch 339/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1816 - val_acc: 0.8140\n",
            "Epoch 340/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1816 - val_acc: 0.8140\n",
            "Epoch 341/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1814 - val_acc: 0.8140\n",
            "Epoch 342/1000\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1813 - val_acc: 0.8140\n",
            "Epoch 343/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1812 - val_acc: 0.8140\n",
            "Epoch 344/1000\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1812 - val_acc: 0.8140\n",
            "Epoch 345/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1811 - val_acc: 0.8140\n",
            "Epoch 346/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1810 - val_acc: 0.8140\n",
            "Epoch 347/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1810 - val_acc: 0.8140\n",
            "Epoch 348/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1808 - val_acc: 0.8140\n",
            "Epoch 349/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1807 - val_acc: 0.8140\n",
            "Epoch 350/1000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1808 - val_acc: 0.8140\n",
            "Epoch 351/1000\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1808 - val_acc: 0.8140\n",
            "Epoch 352/1000\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1807 - val_acc: 0.8140\n",
            "Epoch 353/1000\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1805 - val_acc: 0.8140\n",
            "Epoch 354/1000\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1804 - val_acc: 0.8140\n",
            "Epoch 355/1000\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1803 - val_acc: 0.8140\n",
            "Epoch 356/1000\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1803 - val_acc: 0.8140\n",
            "Epoch 357/1000\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1802 - val_acc: 0.8140\n",
            "Epoch 358/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1802 - val_acc: 0.8140\n",
            "Epoch 359/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1802 - val_acc: 0.8140\n",
            "Epoch 360/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1802 - val_acc: 0.8140\n",
            "Epoch 361/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1801 - val_acc: 0.8140\n",
            "Epoch 362/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1801 - val_acc: 0.8140\n",
            "Epoch 363/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1801 - val_acc: 0.8140\n",
            "Epoch 364/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1801 - val_acc: 0.8140\n",
            "Epoch 365/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1799 - val_acc: 0.8140\n",
            "Epoch 366/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.1799 - val_acc: 0.8140\n",
            "Epoch 367/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1800 - val_acc: 0.8140\n",
            "Epoch 368/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1800 - val_acc: 0.8140\n",
            "Epoch 369/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1798 - val_acc: 0.8140\n",
            "Epoch 370/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1798 - val_acc: 0.8140\n",
            "Epoch 371/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1797 - val_acc: 0.8140\n",
            "Epoch 372/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1797 - val_acc: 0.8140\n",
            "Epoch 373/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1796 - val_acc: 0.8140\n",
            "Epoch 374/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1796 - val_acc: 0.8140\n",
            "Epoch 375/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1798 - val_acc: 0.8140\n",
            "Epoch 376/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.1793 - val_acc: 0.8140\n",
            "Epoch 377/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0230 - acc: 0.9763 - val_loss: 0.1794 - val_acc: 0.8140\n",
            "Epoch 378/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0228 - acc: 0.9763 - val_loss: 0.1798 - val_acc: 0.8140\n",
            "Epoch 379/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0259 - acc: 0.9704 - val_loss: 0.1936 - val_acc: 0.7907\n",
            "Epoch 380/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0221 - acc: 0.9763 - val_loss: 0.2096 - val_acc: 0.7674\n",
            "Epoch 381/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0253 - acc: 0.9704 - val_loss: 0.1935 - val_acc: 0.7907\n",
            "Epoch 382/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2037 - val_acc: 0.7674\n",
            "Epoch 383/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0237 - acc: 0.9704 - val_loss: 0.1949 - val_acc: 0.7907\n",
            "Epoch 384/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0225 - acc: 0.9704 - val_loss: 0.2138 - val_acc: 0.7674\n",
            "Epoch 385/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0278 - acc: 0.9645 - val_loss: 0.1857 - val_acc: 0.7907\n",
            "Epoch 386/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0305 - acc: 0.9645 - val_loss: 0.1746 - val_acc: 0.8140\n",
            "Epoch 387/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0270 - acc: 0.9704 - val_loss: 0.1819 - val_acc: 0.8140\n",
            "Epoch 388/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0182 - acc: 0.9822 - val_loss: 0.1968 - val_acc: 0.7907\n",
            "Epoch 389/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0185 - acc: 0.9822 - val_loss: 0.1920 - val_acc: 0.7907\n",
            "Epoch 390/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0176 - acc: 0.9822 - val_loss: 0.1804 - val_acc: 0.8140\n",
            "Epoch 391/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0188 - acc: 0.9822 - val_loss: 0.1856 - val_acc: 0.7907\n",
            "Epoch 392/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0186 - acc: 0.9822 - val_loss: 0.1921 - val_acc: 0.7907\n",
            "Epoch 393/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0179 - acc: 0.9822 - val_loss: 0.1792 - val_acc: 0.8140\n",
            "Epoch 394/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0189 - acc: 0.9763 - val_loss: 0.1899 - val_acc: 0.7907\n",
            "Epoch 395/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0177 - acc: 0.9822 - val_loss: 0.1941 - val_acc: 0.7907\n",
            "Epoch 396/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0174 - acc: 0.9822 - val_loss: 0.1850 - val_acc: 0.7907\n",
            "Epoch 397/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0174 - acc: 0.9822 - val_loss: 0.1817 - val_acc: 0.8140\n",
            "Epoch 398/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0174 - acc: 0.9822 - val_loss: 0.1811 - val_acc: 0.8140\n",
            "Epoch 399/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0174 - acc: 0.9822 - val_loss: 0.1818 - val_acc: 0.8140\n",
            "Epoch 400/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0173 - acc: 0.9822 - val_loss: 0.1825 - val_acc: 0.7907\n",
            "Epoch 401/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0173 - acc: 0.9822 - val_loss: 0.1823 - val_acc: 0.7907\n",
            "Epoch 402/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0173 - acc: 0.9822 - val_loss: 0.1824 - val_acc: 0.7907\n",
            "Epoch 403/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0173 - acc: 0.9822 - val_loss: 0.1826 - val_acc: 0.7907\n",
            "Epoch 404/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0173 - acc: 0.9822 - val_loss: 0.1829 - val_acc: 0.7907\n",
            "Epoch 405/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0173 - acc: 0.9822 - val_loss: 0.1825 - val_acc: 0.7907\n",
            "Epoch 406/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0173 - acc: 0.9822 - val_loss: 0.1823 - val_acc: 0.7907\n",
            "Epoch 407/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0173 - acc: 0.9822 - val_loss: 0.1821 - val_acc: 0.7907\n",
            "Epoch 408/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0173 - acc: 0.9822 - val_loss: 0.1818 - val_acc: 0.8140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sYpy54d2t4H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "8a0b6a1c-7ae5-4679-c705-4c841127dca1"
      },
      "source": [
        "### 12. What does the plot generated by this code represent?\n",
        "\n",
        "plt.plot(output.history['acc'])\n",
        "plt.plot(output.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "#plt.savefig('Accuracy.png',dpi=100) #to save the image\n",
        "plt.show()\n",
        "\n",
        "# The plot generated by this code represents the model's accuracy over epochs during training and validation."
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABe7klEQVR4nO3deXhTZfo38O9J0qQbTVu6UkpbtkIFyiZYNhmtFlDcFRyVTeEVYQbsoIJsDjpWHWFAXHB+IzoqIyiCOsKoWDbFCrLvW1mK0JXSfU+e9480adKme3LSpN/PdeVqcnJy8jxJe87d+9kkIYQAERERkYtQOLoARERERLbE4IaIiIhcCoMbIiIicikMboiIiMilMLghIiIil8LghoiIiFwKgxsiIiJyKQxuiIiIyKUwuCEiIiKXwuCGiGzm0qVLkCQJH330UbNfu3PnTkiShJ07d9q8XETUvjC4ISIiIpfC4IaIiIhcCoMbIiI7Ki4udnQRiNodBjdELuSll16CJEk4e/YsHn/8cWi1WgQGBmLx4sUQQuDKlSu499574ePjg5CQECxfvrzOMbKysvDkk08iODgY7u7uiI2Nxb///e86++Xl5WHKlCnQarXw9fXF5MmTkZeXZ7Vcp0+fxkMPPQR/f3+4u7tj8ODB+Oabb1pUx8uXL+OZZ55BdHQ0PDw80LFjRzz88MO4dOmS1TI+++yziIyMhEajQefOnTFp0iTk5OSY9ikrK8NLL72Enj17wt3dHaGhoXjggQeQmpoKoP6+QNb6F02ZMgXe3t5ITU3FuHHj0KFDBzz22GMAgJ9++gkPP/wwunTpAo1Gg/DwcDz77LMoLS21+nk98sgjCAwMhIeHB6Kjo7Fw4UIAwI4dOyBJEjZv3lzndf/5z38gSRJSUlKa+7ESuRSVowtARLY3YcIE9O7dG6+99hq2bNmCV155Bf7+/nj//fdx22234fXXX8e6deswb9483HzzzRg1ahQAoLS0FKNHj8b58+cxe/ZsREVF4YsvvsCUKVOQl5eHOXPmAACEELj33nvx888/4+mnn0bv3r2xefNmTJ48uU5ZTpw4geHDhyMsLAzz58+Hl5cXPv/8c9x333348ssvcf/99zerbr/99ht++eUXTJw4EZ07d8alS5fw3nvvYfTo0Th58iQ8PT0BAEVFRRg5ciROnTqFadOmYeDAgcjJycE333yD33//HQEBAdDpdLj77ruRnJyMiRMnYs6cOSgsLMS2bdtw/PhxdOvWrdmffVVVFRISEjBixAi8+eabpvJ88cUXKCkpwcyZM9GxY0fs27cPq1evxu+//44vvvjC9PqjR49i5MiRcHNzw4wZMxAZGYnU1FT897//xd/+9jeMHj0a4eHhWLduXZ3Pbt26dejWrRvi4uKaXW4ilyKIyGUsXbpUABAzZswwbauqqhKdO3cWkiSJ1157zbT9xo0bwsPDQ0yePNm0beXKlQKA+PTTT03bKioqRFxcnPD29hYFBQVCCCG++uorAUC88cYbFu8zcuRIAUB8+OGHpu2333676Nu3rygrKzNt0+v1YtiwYaJHjx6mbTt27BAAxI4dOxqsY0lJSZ1tKSkpAoD4+OOPTduWLFkiAIhNmzbV2V+v1wshhFi7dq0AIFasWFHvPvWV6+LFi3XqOnnyZAFAzJ8/v0nlTkpKEpIkicuXL5u2jRo1SnTo0MFim3l5hBBiwYIFQqPRiLy8PNO2rKwsoVKpxNKlS+u8D1F7w2YpIhf01FNPme4rlUoMHjwYQgg8+eSTpu2+vr6Ijo7GhQsXTNu2bt2KkJAQPProo6Ztbm5u+POf/4yioiLs2rXLtJ9KpcLMmTMt3udPf/qTRTlyc3Oxfft2PPLIIygsLEROTg5ycnJw/fp1JCQk4Ny5c7h69Wqz6ubh4WG6X1lZievXr6N79+7w9fXFwYMHTc99+eWXiI2NtZoZkiTJtE9AQECdcpvv0xLmn4u1chcXFyMnJwfDhg2DEAKHDh0CAGRnZ2P37t2YNm0aunTpUm95Jk2ahPLycmzcuNG0bcOGDaiqqsLjjz/e4nITuQoGN0QuqPaFUavVwt3dHQEBAXW237hxw/T48uXL6NGjBxQKy1ND7969Tc8bf4aGhsLb29tiv+joaIvH58+fhxACixcvRmBgoMVt6dKlAAx9fJqjtLQUS5YsQXh4ODQaDQICAhAYGIi8vDzk5+eb9ktNTUWfPn0aPFZqaiqio6OhUtmuhV6lUqFz5851tqelpWHKlCnw9/eHt7c3AgMDceuttwKAqdzGQLOxcvfq1Qs333wz1q1bZ9q2bt063HLLLejevbutqkLktNjnhsgFKZXKJm0DDP1n7EWv1wMA5s2bh4SEBKv7NPdi/Kc//Qkffvgh5s6di7i4OGi1WkiShIkTJ5rez5bqy+DodDqr2zUaTZ3gUKfT4Y477kBubi5eeOEF9OrVC15eXrh69SqmTJnSonJPmjQJc+bMwe+//47y8nL8+uuvePvtt5t9HCJXxOCGiEwiIiJw9OhR6PV6iwv06dOnTc8bfyYnJ6OoqMgie3PmzBmL43Xt2hWAoWkrPj7eJmXcuHEjJk+ebDHSq6ysrM5IrW7duuH48eMNHqtbt27Yu3cvKisr4ebmZnUfPz8/AKhzfGMWqymOHTuGs2fP4t///jcmTZpk2r5t2zaL/YyfV2PlBoCJEyciMTERn332GUpLS+Hm5oYJEyY0uUxErozNUkRkMm7cOGRkZGDDhg2mbVVVVVi9ejW8vb1NzSjjxo1DVVUV3nvvPdN+Op0Oq1evtjheUFAQRo8ejffffx/p6el13i87O7vZZVQqlXWyTatXr66TSXnwwQdx5MgRq0Omja9/8MEHkZOTYzXjYdwnIiICSqUSu3fvtnj+3XffbVaZzY9pvL9q1SqL/QIDAzFq1CisXbsWaWlpVstjFBAQgLFjx+LTTz/FunXrMGbMmDrNjkTtFTM3RGQyY8YMvP/++5gyZQoOHDiAyMhIbNy4EXv27MHKlSvRoUMHAMD48eMxfPhwzJ8/H5cuXUJMTAw2bdpk0efF6J133sGIESPQt29fTJ8+HV27dkVmZiZSUlLw+++/48iRI80q4913341PPvkEWq0WMTExSElJwY8//oiOHTta7Pfcc89h48aNePjhhzFt2jQMGjQIubm5+Oabb7BmzRrExsZi0qRJ+Pjjj5GYmIh9+/Zh5MiRKC4uxo8//ohnnnkG9957L7RaLR5++GGsXr0akiShW7du+Pbbb5vVV6hXr17o1q0b5s2bh6tXr8LHxwdffvmlRX8no7feegsjRozAwIEDMWPGDERFReHSpUvYsmULDh8+bLHvpEmT8NBDDwEAXn755WZ9jkQuzVHDtIjI9oxDwbOzsy22T548WXh5edXZ/9ZbbxU33XSTxbbMzEwxdepUERAQINRqtejbt6/FcGej69eviyeeeEL4+PgIrVYrnnjiCXHo0KE6w6OFECI1NVVMmjRJhISECDc3NxEWFibuvvtusXHjRtM+TR0KfuPGDVP5vL29RUJCgjh9+rSIiIiwGNZuLOPs2bNFWFiYUKvVonPnzmLy5MkiJyfHtE9JSYlYuHChiIqKEm5ubiIkJEQ89NBDIjU11bRPdna2ePDBB4Wnp6fw8/MT/+///T9x/Phxq0PBrX3OQghx8uRJER8fL7y9vUVAQICYPn26OHLkiNXP6/jx4+L+++8Xvr6+wt3dXURHR4vFixfXOWZ5ebnw8/MTWq1WlJaWNvi5EbUnkhB27E1IRER2U1VVhU6dOmH8+PH44IMPHF0cojaDfW6IiJzUV199hezsbItOykQEMHNDRORk9u7di6NHj+Lll19GQECAxeSFRMTMDRGR03nvvfcwc+ZMBAUF4eOPP3Z0cYjaHGZuiIiIyKUwc0NEREQuhcENERERuZR2N4mfXq/HtWvX0KFDh1at+ktERETyEUKgsLAQnTp1qrN+W23tLri5du0awsPDHV0MIiIiaoErV66gc+fODe7j0OBm9+7d+Pvf/44DBw4gPT0dmzdvxn333dfga3bu3InExEScOHEC4eHhWLRoEaZMmdLk9zROH3/lyhX4+Pi0ovREREQkl4KCAoSHh5uu4w1xaHBTXFyM2NhYTJs2DQ888ECj+1+8eBF33XUXnn76aaxbtw7Jycl46qmnEBoaioSEhCa9p7EpysfHh8ENERGRk2lKlxKHBjdjx47F2LFjm7z/mjVrEBUVheXLlwMAevfujZ9//hn/+Mc/mhzcEBERkWtzqtFSKSkpiI+Pt9iWkJCAlJSUel9TXl6OgoICixsRERG5LqcKbjIyMhAcHGyxLTg4GAUFBSgtLbX6mqSkJGi1WtONnYmJiIhcm8uPllqwYAESExNNj40dkhqj0+lQWVlpz6K5LDc3NyiVSkcXg4iI2imnCm5CQkKQmZlpsS0zMxM+Pj7w8PCw+hqNRgONRtPk9xBCICMjA3l5ea0parvn6+uLkJAQziVERESyc6rgJi4uDlu3brXYtm3bNsTFxdnsPYyBTVBQEDw9PXlxbiYhBEpKSpCVlQUACA0NdXCJiIiovXFocFNUVITz58+bHl+8eBGHDx+Gv78/unTpggULFuDq1aumVW+ffvppvP3223j++ecxbdo0bN++HZ9//jm2bNlik/LodDpTYNOxY0ebHLM9MmbRsrKyEBQUxCYqIiKSlUM7FO/fvx8DBgzAgAEDAACJiYkYMGAAlixZAgBIT09HWlqaaf+oqChs2bIF27ZtQ2xsLJYvX45//etfNhsGbuxj4+npaZPjtWfGz5D9loiISG4OzdyMHj0aQoh6n//oo4+svubQoUN2LFXTJgiihvEzJCIiR3GqoeBEREREjWFwQ3VERkZi5cqVji4GERFRizjVaCmq3+jRo9G/f3+bBCW//fYbvLy8Wl8oIiIiB2Bw004IIaDT6aBSNf6VBwYGylAiIiJypBvFFSiuqKqzvaOXBu5uCmQWlKNKr2/RsdUqBYI6uLe2iC3G4MYFTJkyBbt27cKuXbuwatUqAMCHH36IqVOnYuvWrVi0aBGOHTuGH374AeHh4UhMTMSvv/6K4uJi9O7dG0lJSRZrdkVGRmLu3LmYO3cuAEPn4P/7v//Dli1b8P333yMsLAzLly/HPffc44jqEhFRK+04nYUn//0b9FbG9Ph7qRHfOwif7/+9xccf2MUXm54Z3ooStg6Dm0YIIVBaqXPIe3u4KZs06mjVqlU4e/Ys+vTpg2XLlgEATpw4AQCYP38+3nzzTXTt2hV+fn64cuUKxo0bh7/97W/QaDT4+OOPMX78eJw5cwZdunSp9z3++te/4o033sDf//53rF69Go899hguX74Mf39/21SWiIhk89O5HOgFoFRIUClqrjMVOj1yiytMgY1aqUBLBr+6KR3bpZfBTSNKK3WIWfK9Q9775LIEeKob/4q0Wi3UajU8PT0REhICADh9+jQAYNmyZbjjjjtM+/r7+yM2Ntb0+OWXX8bmzZvxzTffYPbs2fW+x5QpU/Doo48CAF599VW89dZb2LdvH8aMGdOiuhERkeOk5RYDAF665yY8cUuEaXvS/07h/V0XAACeaiUOL7kTapXzjT1icOPiBg8ebPG4qKgIL730ErZs2YL09HRUVVWhtLTUYrJEa/r162e67+XlBR8fH9MSC7ZWVqlDQVklArw0UCis/8tQXF6F0kodOnqpodML5JZUwNdDDbVKgdziClM7sZtCAT8vNcqrdMgvbTsTCnprVPBUq1BQVokyB2UGiZyZUpLQ0bvxdQOLy6us9itxVRqVEloPt0b3u3S9BAAQ4W85ae2tPQJNwU1c145OGdgADG4a5eGmxMlltpkBuSXv3Vq1Rz3NmzcP27Ztw5tvvonu3bvDw8MDDz30ECoqKho8jpub5R+LJEnQN7OjWWmFDne99RP8vNTY+HSc1Sa3a3mlSFi5G4VlVRgc4YcvrOx3+EoeHl7zCyp1AvfEdsKJa/lIzS5GsI8Gt/cOxn/2WgZqk+Mi8O3RdFwvbriOclKrFHhyRBTW7EpFA/NYElEDnhoRhUV3x9T7vPm5or2QJOCZ0d3w4Z5LeHBgZ+w+l43gDu7Y8P9uMZ1L9XqBtNzq4KajZXAzKNIPHm5KlFbqMLJHgOzltxUGN42QJKlJTUOOplarodM1ngHYs2cPpkyZgvvvvx+AIZNz6dIlO5fOIOVCDi7kFAM5xTiTWYheIT519vn+RAYKywz/Ze2/fAOXrpcgKsAyQPvq0FXTyeqbI9dM2zMLyk2BjTEeEgL4d8pl0z71JIJkpRdARZUe7+1MBWAoaxsoFpHTEDD8bW88+DsWjOsNZT1/2Obnirbwt29vxs/lnR2Gc8snvxrOfZevlyA1uwjdgzoAADILy1BRpYdKISHM18PiGBqVEk+OiMIPJzNwV79Ospbfltr+VZuaJDIyEnv37sWlS5fg7e1db1alR48e2LRpE8aPHw9JkrB48eJmZ2BaavfZHNP9n87mWA1ufjqXY/F499nsOsHNT+eyG3wfL7USh5bciSq9Hv3/ug0VOkP9/nxbdyTeGd3S4tvM14evYs76w6bH/5sz0upnQUTWVer0GLhsG/JKKnH8aj5iw32t7mc8V7z32ECM7RsqYwkd43xWIeJX7Lb63O6zOabg5nJ1k1SYnwdUVjr+zkuIxrwEx58rW8M5G9Oojnnz5kGpVCImJgaBgYH19qFZsWIF/Pz8MGzYMIwfPx4JCQkYOHCgLGXcbRaU7DybhfySStOttEKH8iodUlKvAwDuiTX8x7DlaDqqdDXB1/msQqRmF0MhAXeZnayM+wNAXLcAqFUKeKpVGBzpZ9o+qmfbmL9nZI9AU2YpqIMG0cEdHFsgIifjplRgWPeOAIBvj16DEAJCCItzytnMmnPFsO7O27zSHN0CvdFJa31umW+PXkNl9bk0rTq46eLvuotEM3PjInr27ImUlBSLbVOmTKmzX2RkJLZv326xbdasWRaPazdTWVvcNC8vr1nl+/1GCS5kF5se7zl/HbHLfjA9ViokPDokHKWVOgR4azBjVFd8c+Qa9l3KxYjXd2Bb4ih8fyIT8744AgDoH+6Lu/qFYsuxdADAvDuj8d2JDFRU6TGqZ82JbGSPQPySeh0dNKp6/7uTm7+XGn06aXHsan51oNMO8uVENjayRyC+P5GJ//vpIk5nFMLDTYkfTmbW2a9/uG+TOti6AkmSMLJHIDbsv1LnuYNpeRj22nb8MHcULl43nItr97dxJczckCyMzU0Du/ha7aSm0wt8+qsh2zSqRwBiQn0wJMowh05GQRmOXc1H8qmaE9djQyNwa89A9Anzwf0DwtCloyeeuCUCXQO8MLZPTUbn3v6d0MXfE1OGRzp83gVz00ZEIsBbg8duqX9uISKqX8JNIaag5adzOUg+XXf0pptSwmNDI+psd2V/HNoFgR00eHFcL/QI8sYTt0Qgrqshy5VdWI7tp7Ow/1IuAKB3qOs2h0vC2r/lLqygoABarRb5+fnw8bH8YsvKynDx4kVERUXB3d1x00a7gtqf5TPrDmDrsQzMje+BufE9LZqaTmcU4u7VP5se/2NCLO4f0BlCCDzxwT78fD4HSQ/0xccpl3EqvQD/mjQY8THBjqgWEbUhQgj0fekHFJUbBiGoVQocfynB1HlYkqR6Oxu3J0IIvPbdaby/6wLiewdhx5ls6PQCPz3/B4Q7UdNUQ9fv2trOv7LkssoqdUg+ZfivytjvRaVUmG43dfJBgNl8FSO6G/aRJAldAw2diS9fL0FadSo1MoCLehKR5TkCMPQhUatqzi0MbAwkScIfooMAAD+eyoJOLxAV4OVUgU1zMbihegkhcCG7CKlZRVb73dR2KacYZzMLkZFfivNZRajS6XHiah56Lf4O5VV6+Lir0C9MW+d1kiRhVHVTVUyoDwI71AQ6xg5vB9NuoLhCB0kCwv096hyDiNon806xkS7ch6S1Bnbxg5e6Zu40Z57DpikY3FC9KnV6FFXP7llS0fAcOuXVswqXVeqQVVgOnV6PonIdvj9R00/m0aFdrA47BAztxD7uKkwZFmmxPbKj4b+yfRcNbcShPu7QqFo/uSERuQbjOQIAuvgzq1sftUqBCTcb+vh5uCnxwMDODi6RfXG0FNWroqqmX0xReRW8NPX/uhjbvC0J/HbpBgBgzeMDMaZP/fNMDI70x9GX6s4EXbs3fxf+Z0ZEZszPCa48+scWloyPwfNjoqFUSG1qgIU9MLihepucys2Cm8KyKgR1qL9pyjircO3XZxWWQa1UtHiOmdptwhH8z4yIzJivjcR/fhrnboNlfZwBg5t2Lj2/FNmF5Y3uV1JRhWNX85t1bOO054Mj/Vq8hIW7mxKhWnek55cBACICePIiohrmAwzMm6iofXPtvBQ1SC8ErhfZbjFJD7USfp7qOttbOzNwwk0hAAB3NwVGdm8bswwTUdsQ1EGD/uG+6BXSAeF+HGxABszctGMlFTrohYBKoUDPYG+L585lFZmm6o7s6AVPdeOpTKVCgiRJCPPzwPHLNWtEtbZX/kv33ITEO3tCrVS0m5QqETWNJEnYNHMYAEDBod9UjZkbFzF69GjMnTu3Wa8pKqsEAHi7qyzmnVEpFViS+AzmPvkYAFjMG9HQzbiMgEKSoFIa7vt6qtHbBotC+ri7MbAhIqsUComBDVlgcNOOFVaPcOpgZRSUyuxEoW5Br3q36uBmcIQfTzpERCQrBjcuYMqUKdi1axdWrVoFSTI0DV26dAnHjx/H2LFj4e3tjeDgYDzxxBPIyTE0Fwkh8M3mzXgwfhg6BWjRsWNHxMfHo7i4GC+99BLW/+dT7PhhK2LD/aBUKrBz585mlclb4wZJAsb2DbFDjYmIiOrHPjeNEQKoLHHMe7t5Ak1YMXrVqlU4e/Ys+vTpg2XLlhle6uaGIUOG4KmnnsI//vEPlJaW4oUXXsAjjzyC7du3I+33a5g/+0k8u/CvmDn5URQVFeGnn36CEALz5s3DqVOnUFBQgA8//BAA4O/v36yi+3mpEebrgahwv+bXm4iIqBUY3DSmsgR4tZNj3vvFa4C68aGNWq0WarUanp6eCAkxZEpeeeUVDBgwAK+++qppv7Vr1yI8PBxnz55F1vU8VFVVYcxd9yIqKgoA0LdvX9O+Hh4eKC8vNx2PiIjIWTC4cVFHjhzBjh074O3tXee51NRUDB5+K4aOuBX33haHMWMScOedd+Khhx6Cnx8zLURE5NwY3DTGzdOQQXHUe7dQUVERxo8fj9dff73Oc6GhoSiokvD+fzbj4olDOJSyC6tXr8bChQuxd+9eUyaHiIjIGTG4aYwkNalpyNHUajV0uprFLQcOHIgvv/wSkZGRUKnqfs0514shSRKGDx+O+8bchiVLliAiIgKbN29GYmJineMRERE5C46WchGRkZHYu3cvLl26hJycHMyaNQu5ubl49NFH8dtvvyE1NRXff/89pk6dCp1Oh9/27cW/Vi/HiSOHkJaWhk2bNiE7Oxu9e/c2He/o0aM4c+YMcnJyUFlZ6eAaEhERNQ2DGxcxb948KJVKxMTEIDAwEBUVFdizZw90Oh3uvPNO9O3bF3PnzoVWq8XF6yVQuXvhwN4UPPLAPejZsycWLVqE5cuXY+zYsQCA6dOnIzo6GoMHD0ZgYCD27Nnj4BoSERE1jSTqWxLaRRUUFECr1SI/Px8+PpYz55aVleHixYuIioqCu7u7g0poX4VllbiYUwzAMDlfz5AOUDRhuHlztYfPkoiI5NPQ9bs29rlpZ4rKDLMSe6lViArwsktgQ0RE5EhslmpnjEsudPRWc1kEIiJySczcuLiisir8fqMEAkCgtwZllYYRUN5W1pMiIiJyBbzCubi8kgpU6PQAgPT8UgCAp1oJVQsWwyQiInIGvMJZ4Up9rMurAxsAMNbKW+Nm9/d1pc+QiIicC4MbM25uhot+SYmDFsq0g4oqfZ1t3u72T9gZP0PjZ0pERCQXNkuZUSqV8PX1RVZWFgDA09MTkpOOJrpRUoGC0kpUVPex8XF3Q0FZJSRJgkJfibLqUVO2JoRASUkJsrKy4OvrC6VSaZf3ISIiqg+Dm1qMq2AbAxxnlZ5fBp3e0DSkkAB4a5BdWA5PjRKXS9R2f39fX1+uKE5ERA7B4KYWSZIQGhqKoKAgp11yIDWrCIs37Tc97hHsjTWPxyC4pAJeGhXc7NyZ2M3NjRkbIiJyGAY39VAqlU57gd5z6SquFtYsetkrTAN3d3eEcKZgIiJqB9ih2AXtPptj8Tiv1DkzUERERC3B4MbFlFbosO9SLgDgjphgAMDc+B6OLBIREZGs2CzlYvZdykVFlR6hWneseXwQcorKEezD5igiImo/mLlxMbvPZgMARvUIhFIhMbAhIqJ2h5kbJ3YltwTPbjiMvNJKSADuHxiGn84ZgpuRPQMcWzgiIiIHYXDjxL49mo79l2+YHq/44Syq9AKSBIzozuCGiIjaJzZLObHL14sBAI8M7oxQrTuqqift69fZF76e9p+oj4iIqC1icOPELl83rN90S9eOuLVnoGn7rT2YtSEiovaLwY0TS8s1BDcRHb0wskdNcDPSLNAhIiJqb9jnxkmVV+lwLb8UABDR0RPdA73h5+kGT7UK/cN9HVs4IiIiB2Jw46Su5JZCCMBLrURHLzUkScJ3c0dBpZDsvnYUERFRW8bgxkml5Ro6E3fp6AVJkgCAc9oQERGBwY3TST6Via8OX0O3QC8AQIS/p4NLRERE1LY4vP3inXfeQWRkJNzd3TF06FDs27ev3n0rKyuxbNkydOvWDe7u7oiNjcV3330nY2kd729bT+G/R67h3Z2pAIBuQV4OLhEREVHb4tDgZsOGDUhMTMTSpUtx8OBBxMbGIiEhAVlZWVb3X7RoEd5//32sXr0aJ0+exNNPP437778fhw4dkrnkjvH7jRJcyDY0R1VU6QEAw7tx2DcREZE5hwY3K1aswPTp0zF16lTExMRgzZo18PT0xNq1a63u/8knn+DFF1/EuHHj0LVrV8ycORPjxo3D8uXLZS65Y+w+m2Px2MNNiUGRfg4qDRERUdvksOCmoqICBw4cQHx8fE1hFArEx8cjJSXF6mvKy8vh7m7ZadbDwwM///xzve9TXl6OgoICi5uzMq4bZXRLV39oVEoHlYaIiKhtclhwk5OTA51Oh+DgYIvtwcHByMjIsPqahIQErFixAufOnYNer8e2bduwadMmpKen1/s+SUlJ0Gq1plt4eLhN6yGnw1fyAMA0j83YvqGOKwwREVEb5fAOxc2xatUq9OjRA7169YJarcbs2bMxdepUKBT1V2PBggXIz8833a5cuSJjiW2nrFKH9PwyAMB7jw/E5meG4eFBnR1cKiIiorbHYcFNQEAAlEolMjMzLbZnZmYiJCTE6msCAwPx1Vdfobi4GJcvX8bp06fh7e2Nrl271vs+Go0GPj4+FjdndKV6qYUOGhVCfNwxoIufaX4bIiIiquGw4EatVmPQoEFITk42bdPr9UhOTkZcXFyDr3V3d0dYWBiqqqrw5Zdf4t5777V3cR3OuEhml46eDGqIiIga4NBJ/BITEzF58mQMHjwYQ4YMwcqVK1FcXIypU6cCACZNmoSwsDAkJSUBAPbu3YurV6+if//+uHr1Kl566SXo9Xo8//zzjqyGLC6bFsnkpH1EREQNcWhwM2HCBGRnZ2PJkiXIyMhA//798d1335k6GaelpVn0pykrK8OiRYtw4cIFeHt7Y9y4cfjkk0/g6+vroBrI5/L16uUW/DlpHxERUUMkIYRwdCHkVFBQAK1Wi/z8fKfqfzN57T7sOpuN1x7oi4lDuji6OERERLJqzvXbqUZLtWdpuTV9boiIiKh+DG6cQEFZpSm46Rrg7eDSEBERtW0MbpzAL+evQ6cX6BrghRCte+MvICIiascY3DgB47ILo3oGOrgkREREbR+DmzZOCIHd1cHNyB5cAZyIiKgxDG7auJyiClzJLYVCAm7p2tHRxSEiImrzGNy0ccb5bUK1HvDSOHRaIiIiIqfA4KaNMy67wJmJiYiImobBTRtnzNwwuCEiImoaBjdtXM2aUlx2gYiIqCkY3LRxpmYpf2ZuiIiImoLBTRvHZReIiIiah8Nv2pisgjK8tf0cSsp10AuB3OIKAGyWIiIiaioGN23M+7sv4NNf0yy2hfl6wJvDwImIiJqEV8w2ZvdZw2zEjw7pgq4BhmzNyJ6cmZiIiKipGNy0IdfySnEuqwgKCZg/phe0nm6OLhIREZHTYYdiB/vpXDY2/GZohvr5XA4AIDbcl4ENERFRCzFz42BPfLAPANDJ1wO7TAtkcvVvIiKilmJwIxchgPTDQGmeaVOFTo/himMAgCOHJew5b/g6RhlX/84+CxRcrTlGx+6Ab7hMBSYiInJODG7kcvxL4MsnLTapAaxTVz84AWwu/zt0mgj0D/cFsk4D7w61PIabJ5B4CvDwlaHAREREzonBjVxyLxp+evgBPmEAgNJKHS7lFKOLlAkvqRzdpavo3n0gVEoFkH3KsL+bF+AfBWSfBipLgPwrDG6IiIgawA7FctEZJuNDn4eAmXuAmXvwc/zXGFvxGlL0MQAAX6kYf4gOMuxXesPws+tow/7+3Sy3ExERkVXM3MjFGNwo1aZNOUXlAIBKtRbQAQ/FeKL/oM6GJ41BjIef5U8GN0RERA1i5kYuukrDT2XNEO/sQkNw08HXMDrq5iAJbsrqr8QU3PhW/2RwQ0RE1BTM3MilOnNzJL0E2pxiHL+Wjy1H0wEAkjFwKcur2d84qsqUufG13E5ERERWMbiRS3Vws+3MDbx9cqfFUypvf8Md86wMm6WIiIhahM1Scqlulqq0Ek+qO3Q03LEIbvIMPxncEBERNQuDG7lUZ26qoKzzlKe2ekZiZm6IiIhajcGNXKqDmwormRtv3+oZic370zC4ISIiahEGN3Kp1SwV4K0xPeXbMdhwp8HMjW/19jw7FpKIiMj5sUOxTKoqy6ECUClUWDo+BjdH+uN6cQX0QsBLW/01VBQBVRWA0AFVpYZtzNwQERE1C4MbmZSVlcEbgLu7O6YOj7J8Uq8DIAEQhuHgep1hu6QENB0M9xncEBERNQmbpWRSUVEGAPDt4FX3SYUScNca7pfesGySkqSa+wBQWQxUldu5tERERM6LwY1MqioNHYq13laCG8AyM1O7vw0AaLQwZHfAfjdEREQNYHAjE6l6tJRKrba+gzGQObwOOPJZ9TbfmucViprHv74LHPoUqCwDhABOfg3kpTWtIGf+B+Scb3b5iYiInAX73MhEIQyjpYSinuDGu3o18IMf12zzCrLcxyvIkNXZs9LwWF9lWC3880lAt9uBJzY1XIisU8BnE4FOA4EZO5pfCSIiIifA4EYmCn2V4Y6ynuBm9ALAs6PZAptqYOgMy33GvgYcWQ9cOwTknDVkaxTVC3HmX2m8EMbsTnFO8ytARETkJBjcyEShr87cmK0KbqFTf+C+dxs+SLfbDLcdScCu1yz75zRlFJVxn+omMiIiIlfEPjcyUVY3S0n1ZW6aw1rn49Ibhv43DWFwQ0RE7QCDG5k0mrlpDmvBjb7KMAlgQ0zBTWXry0BERNRGMbiRiTFzU2+fm+awFtwYHzeEmRsiImoHGNzIRCmMHYptkbnxNfwszTPMaGzUnOCmsSYsIiIiJ8XgRg5CQGWXPjd5LcvcQNQs8UBERORiGNzIwTgMHACUmvr3aypjcFOebzmsu8nBDdg0RURELovBjRzMAgmFygaZG3ffmvvm89swuCEiImJwIwvzQMIWfW6UKkDjU3d7s4IbjpgiIiLXxOBGDmaBhFJlg+AGsFx3yqih4Eavt1xwk5kbIiJyUQxu5FAdSJQLFZRKG33k5iuGGzW0Wnh5PgCzEVIMboiIyEUxuJFDdSBRCRVUCsk2x7Qa3DSQuan9HJuliIjIRTG4kUN1IFEJFZQKB2Vu6gQ3zNwQEZFr4sKZcjDL3NiqVcoiuJGUgNABl38Gjm00PJd+BBjxLFBwFfjtX4B/V8vXH14HBPUGBk5q3vteTwUOfQrEzQK8Apr2mqoK4KflQI87gM6Dm/d+AHD5F+DibqDvw8Cv7wKVpYBCBdz8lGF71knDfiF9gVtmGsqY8jZQVd789zLX+WYgKAY49Akg9K07llFIP6DLUGD/Ws41RNRqEtDvEaDrrcDZ74GTXwM+YUDsxJpzRXuj9gKGzwW0YdafzzwB7PsnoHI3XCO8Ag3n5y5xQNRI4PRW4MZFwzkeAAozgZ9XAOWFgCQB/R8HIuLqf/+M48CelUBgNDDqOVvXrskY3MihOripsGXmRhtecz98KJD2i+H+V88AHYKBvDTDCuInNgF7VgG+EZav/7V6BfLudwA+oU1/35R3gP0fAJ7+wLA/Ne01v75rWMV812vAS/lNfy+j7xcC1w4CxzcBOWdqtl/ZC2Sfttw3eqyhvgf/3fz3qe3wOqBjD+D6udYfy2QdENATyDlrw2MStWPXDgLPpADfVv8zBxiCHPNzRXuj9gbil1p/btfrhs8HMPwjHDUK2PE3ILgPMHMP8M2fgJIcoOcYoGM34NDHwN41Na/PPAnM2FH/e+deAI59YbguMbhxccZmKaG0XZ+bIdMBdx/DsW96AEhLAb6YDOjKDYENABRnA0VZhvt5l60fpySnecGNcbmHsmYEKZnHm76vNcY6GE9WAdGG+9nVjz0DDJmV0lygyKzOMfcBnQa07D13vQFUFtcENjdPB7SdW1wFAIb/Zkpv1AQ2AycB/t1ad0yi9qow3XDRNZ6LzJvljeeKXncbMrDtxaWfgfPbgOKs+vcpyrK8X5RZc19XZbgmAIbrR8duNfsbz7vF2Q2XwdgFwlrXCRkxuJGDRbOUjYIbTQdDs4zRTfcBX3tbrgxee2FNa5qbtq0sa/7rWtv8UrsOUSOrT17Vo7/8IgF9pSG4Ma9znweBmHta9p4HPjKkZo2GzAACe7bsWEbHN1rWZdAUIGxQ645J1F5lnTIEN5WlhrXyqqyck2LuA/o9LHvRHEbTwRDcNLX/pfn5svSG9bUKjT+N592mzqfm4OCGHYrlYI/RUtbU/mVqSnDT0B+BNcYTSFVZ018jWhHcVJUbMijmavcf8vCzvlJ6a/64ar/WFn+o9jgmUXulcjf8rCozZLCt9Ytrb39j5ufB+tQX3Ogrgfzf6+5n/Gk871YUGfpRNnZ8BjftgMVoKXsGN76Wj5sU3DTyfG2mzE0zgpvWZG6sBV8OCW58W36seo/Zzk68RLbk5mH4WVlqPWsDtL+/scaCGyHqD24AQ38Z8+fMf/pGAKi+fplneGpjcNOOmHUoVtmqQ7E1LcrcNDO4MWVumtEs1ZqRRtbK5xdl+dgiuMm1fXCj7mCbZTMsyiMBGm3rj0nUXhkzNxBAWYH1fWzxT4kzaSy4qSyxnAakOcGNVwDgrm34+ObPtffg5p133kFkZCTc3d0xdOhQ7Nu3r8H9V65ciejoaHh4eCA8PBzPPvssysqakUVwBFOHYntnbmr9MpXkukDmxkr5vIMMowGMzIOb/KuG9Kpxe0uZv9ZWf6QWx/QF7BnoErk6Y+YGqP88xsyNpdrbS/Mss+O5F+vuax6sNKfZqz0HNxs2bEBiYiKWLl2KgwcPIjY2FgkJCcjKst7T+z//+Q/mz5+PpUuX4tSpU/jggw+wYcMGvPjiizKXvJnM+9woZQxu8n8H9FWW28yDAkCmzI0tgxvJ8N9D7eDD+Nj4n4dSY3nya67agYgt2CNgImqvlGqYmkmsnsekmkxDe2E8r1SVWR/0Yfqcqj+38nyg5HrN8zdqBTfmaxI2NbgxNlk5OGvm0OBmxYoVmD59OqZOnYqYmBisWbMGnp6eWLt2rdX9f/nlFwwfPhx//OMfERkZiTvvvBOPPvpoo9keh5Otz02tC6Z5itHIO8jysbNlbty1gEJp+YdjLbjx8DNMONVSds/cMLghahVJqvkHxtp5zHiuaE80HQyTugLWPxNT52Czpv0bl2ru126WMl+T0N23iZmbPMPP9pq5qaiowIEDBxAfH19TGIUC8fHxSElJsfqaYcOG4cCBA6Zg5sKFC9i6dSvGjRtX7/uUl5ejoKDA4iY7U58bG85zY03tX6aijLr7eAdbPm6oY5g1cmduapfPGNS4+1puM9bdWOfW/tdgj8yNRZkZ3BC1mrHfjbWLbXvrbwMYAr6GAhBT/5kgQ19CwDBfkJH5/dK8mv3dvACV2uzYefWXwfga8/OdAzhsnpucnBzodDoEB1tebIODg3H69Gmrr/njH/+InJwcjBgxAkIIVFVV4emnn26wWSopKQl//etfbVr2ZjPL3Chak01oTFN+mVqbuTEuadDSzI1e37y+JrXLZ/zjqp0Fqd381trggZkborbPzQMohVk/D3/DoAKg/f6NefgZJuKzFoDUbmKqKKz/ONZGnjaWuamqqJlrrb1mblpi586dePXVV/Huu+/i4MGD2LRpE7Zs2YKXX3653tcsWLAA+fn5ptuVK1dkLHE1Y58bIXOfm9qU6rpt0M0JboSomd+mOZkbi+CmmauRNzW4sfUwawY3RG1f7cyNT6ea59rr35gxY9VQ5sbDr/HMVkuCG1Om3fH9nRyWuQkICIBSqURmZqbF9szMTISEhFh9zeLFi/HEE0/gqacMM/P27dsXxcXFmDFjBhYuXAiFlYyARqOBRqOxfQWawyxzI2uzlLXnlbU+i+YEN+YT9zUnc2PeLKWrAFTN+D6YuSGi+tTuc+PuC6g8DP98tde/saY0S1n7h7C2snyguLqzsTEQauporDbQ38lhmRu1Wo1BgwYhOTnZtE2v1yM5ORlxcdZXHC0pKakTwCiVhg9QCGG/wraWPRbOtKZJwY3acpuxR3xTmPe+b2nmRmeHzI27b90mOQY3RK6vdubGzd36OaI9sVVwA1GzJmFTMzdtZBg44OC1pRITEzF58mQMHjwYQ4YMwcqVK1FcXIypU6cCACZNmoSwsDAkJSUBAMaPH48VK1ZgwIABGDp0KM6fP4/Fixdj/PjxpiCnTXLU8gvWnq89GZ3QG9pdm5JCbGnmxjyg0TUwbbc1jQU3Gh9AqTLc3DwNk1QBNuhQbPZ6W/2hunkYMme68jbxx0/k9EyZmzzDT1V1cFN4rf3+jTUpuPFt2udjPvq0sWNbHN/xn71Dg5sJEyYgOzsbS5YsQUZGBvr374/vvvvO1Mk4LS3NIlOzaNEiSJKERYsW4erVqwgMDMT48ePxt7/9zVFVaBpHDAU3XkTN71vL3ADA2jGWQY/CzbBUffQYw+NfVhuWsLfIwJTX3zn41H+Bw58B974NePpbZnn+O8eyR35jsk7XrYN5XWsHIabgppV/XEo3w2iCikLb/aEaRzIUZbSJP34ip1cnc+PBzI1p5GgWsHEaEDkSKLgGlBfWn7kxv16YPz71reUxjT8zTwDvj6r73gxuasyePRuzZ8+2+tzOnTstHqtUKixduhRLly6VoWQ2VJ2tqILCvpkbNw9A28XwCxY5HDj7nWF7zD2G4CQw2npwk3Wy7rZf36kJbna+ZrnauFFVGaD2rLs95R0gLQU4fx/Q7xHLLI+xTM2hcAN6JgCnvjHUATD72atmv8BooOBq3e0tFRgNpB8G/Lu1/ljmxyzKBAJ62O6YRO2VW63gRuVu+Bu7/HPNOaK9MQYW57cZzjUXfwKKqyfG9aoeLevha3mO7HEHcG6bIaDx7AiE9AUu7KwZTWXc1z/KcD7WlQPpR+ovgy3Ov63k8OCmPRB6HSQAVfZefkGSgOnbDUGHZ0fgyq+G5qbQAcDwuYY/9pR3avYf9icgarTlMdIPA9tfrjlZVJVbD2yA+oObkuqhmKZj1Oqf4+YJPPJJ0+vlHwVoOwPXzwNBMYZtgdHArN8An9Ca/R75GLiyz7AGSki/ph+/Po9/aZi90/w9WmvCp4YTTu3FP4mo+VS1OhS7eQB3vgLc/GTNuaK9MWVuqgfrFJvN+G+87+EHdL3NcB6qLAbChwKFGcD1VCA4xjAZ4JV9hhGy7logbJDhdd5BwKy9lss01KZSA+G32L5ezcTgRgZCXwUJgA4K+y6cCQDegTX3u91Wcz+kj+GneeamQyjQo2YSRQCGX/rtL9e0YTc0WZO16b2BumuS1O6fo/au+75NEXyT5ePAnpaPNR2A7rc3/7j18fC1/URg7j6GGxG1njFzY/wHSuVuGI1Z+1zRnjSlScjDz9ClIPzmmm3+UZYzF9d3Lu3YzXBr45xqnhtnpdcZhinroIDSnvPcNIV53xrTqrpmas+R0NBQ8SornYqFsHytEFYyN1bel4iouVS11o9rzXpyrqKpwY2LY3AjA1E9B0uVvZdfaArzzI21E4Hxl76iyDDbZEPBjbXMTUVxzUR9pTcMnalFraHmtU9IREQtUfsfJWv/sLU3jQYuEqBx/QVFGdzIQFRnbvRQ2Hf5haYwD26snQjctTCtGFuW1/zMjfn+pTesz4fDzA0R2QIzN3U1OiWIb/OWwHFSrl/DNkBUD6G2+2ippjBvlrJ2IlAoa+a8MZ9+2xprmZvawY21+XCYuSEiW2Dmpq7G5ixrB01SAIMbWRibpfRQQOHw4KaRzA1gOVGT+RDL2qrK626rk7mxEtwwc0NEtsDMTV3m/6Baw+CGbKY6cyOkNjCLcmN9bgDrwY21ocvWmpyaEtwwc0NEtsDMjXUNBTAMbuq3Y8cOW5fDpRn73AgHLyQGoPHRUkDTgxtrTU51mqVK6u7DzA0R2QIzN9bVXmvPHIOb+o0ZMwbdunXDK6+8gitXrti6TK7HuGK11AamFWpx5iaq7n6NZW6EHijKrrsPMzdEZAvM3FjXUADTUODjQloU3Fy9ehWzZ8/Gxo0b0bVrVyQkJODzzz9HRUUzF0VsJ4wdivVtrVmq3syNr+FnazM3gPV1pJi5ISJbYObGOjZLtSy4CQgIwLPPPovDhw9j79696NmzJ5555hl06tQJf/7zn3HkSANrTrRHpsxNWwhuzLJHjWZu8gzDwQGgQ6e6+1nL3Bj3N7IW3DBzQ0S2wMyNdQxuWt+heODAgViwYAFmz56NoqIirF27FoMGDcLIkSNx4sQJW5TR6RkzN22iz40wu9+cPjee/nX3a0rmpuBa3X2YuSEiW2DmxjoGNy0PbiorK7Fx40aMGzcOERER+P777/H2228jMzMT58+fR0REBB5++GFbltV5VQc3UlvI3Ahdzf3m9Lmx9gdhtc9NnuVjZm6IyF6YubGOwU3LFs7805/+hM8++wxCCDzxxBN444030KdPH9PzXl5eePPNN9Gpk5WmjPaoullKKNtAcKM3C27MR06ZM/7ypybX3Wbu55XAL6trHb+6Cc7Ny7Da7Lkf6r6OmRsisgVmbqwznq+N52EAcPM0jF5tJ8FNizI3J0+exOrVq3Ht2jWsXLnSIrAxCggI4JBxo+psiWgLi7B3GgB4BQFhg+vfJzQWUHeoeRwUA3j4AyP/Aig1wB8WVvcfEoZgxvwGGCaQumVm/cfnf1dEZAvazoBPZ8P9gOh2c+FuVOfBhvPsgMcBbRegyzCg6x8AzwAgMNrRpZOFJIQQje/mOgoKCqDVapGfnw8fHx9Z3rN41VB43TiN5z3+ijdemCvLezaoqgJQqBpeX6SipKZzsFdQTUfkyjJD5qU0z/ocNoDhBOPmARRfB3TlhhFae1bWZHnufcfwR0dE1FpVFUBJDuAVWH82uj0ynquN53tJAnQVgErj6JK1WHOu3y1KJSQlJSE4OBjTpk2z2L527VpkZ2fjhRdeaMlhXZexKUjRBjI3AKBSN76P2tNwq83YpOThWzNkvD5eHWvuN2UIOhFRc6nUgA+7QNRhPFebn++dOLBprhY1S73//vvo1atXne033XQT1qxZ0+pCuRrJ2Im3LXQodpSmTB5IRERkAy0KbjIyMhAaGlpne2BgINLTrYyOae+MmZu20KHYUcyzVszcEBGRHbUouAkPD8eePXvqbN+zZw9HSFlhyty0lWYpR2CzFBERyaRFV9vp06dj7ty5qKysxG233QYASE5OxvPPP4+//OUvNi2gS6geRSS1hUn8HMWiWYrBDRER2U+LgpvnnnsO169fxzPPPGNaT8rd3R0vvPACFixYYNMCugJj5ka068yN+Wrk7HNDRET206KrrSRJeP3117F48WKcOnUKHh4e6NGjBzSa9tMTuzmk6j43CmZuDJi5ISIiO2pVKsHb2xs333yzrcriutjnhpkbIiKSTYuvtvv378fnn3+OtLQ0U9OU0aZNm1pdMFdibJaS2nNwA6nmLjM3RERkRy0aLbV+/XoMGzYMp06dwubNm1FZWYkTJ05g+/bt0Gq1ti6j01OYMjftuFnKfMFOZm6IiMiOWhTcvPrqq/jHP/6B//73v1Cr1Vi1ahVOnz6NRx55BF26dLF1GZ0eMzewXLCzHc2SSURE8mtRcJOamoq77roLAKBWq1FcXAxJkvDss8/in//8p00L6ApMwU17nsTPPHMjSfXvR0RE1EotCm78/PxQWFgIAAgLC8Px48cBAHl5eSgpqWcxxfZKCFOzFDM3RERE9teiq+2oUaOwbds29O3bFw8//DDmzJmD7du3Y9u2bbj99tttXUbnJvSmu+06uFE2YbFOIiIiG2jR1fbtt99GWVkZAGDhwoVwc3PDL7/8ggcffBCLFi2yaQGdXvXsxACgULbj4KbvQ8ChT4CoWx1dEiIicnHNvtpWVVXh22+/RUJCAgBAoVBg/vz5Ni+YyzBvjmnPwY2bB/DkD44uBRERtQPN7nOjUqnw9NNPmzI31AizzI2yPXcoJiIikkmLOhQPGTIEhw8ftnFRXJRg5oaIiEhOLbraPvPMM0hMTMSVK1cwaNAgeHl5WTzfr18/mxTOJZg1Synbc4diIiIimbToajtx4kQAwJ///GfTNkmSIISAJEnQ6Tjs16S6WUonJDZLERERyaBFwc3FixdtXQ7XVZ25qYISyhY1AhIREVFztCi4iYiIsHU5XFd15kYPBZScmZeIiMjuWhTcfPzxxw0+P2nSpBYVxiWJmsyNQsHghoiIyN5aFNzMmTPH4nFlZSVKSkqgVqvh6enJ4MZcdbOUHhIUzNwQERHZXYt6gdy4ccPiVlRUhDNnzmDEiBH47LPPbF1G52bR54bBDRERkb3ZrItrjx498Nprr9XJ6rR7xtFSUHIxbCIiIhnYdPyOSqXCtWvXbHlI52cKbtihmIiISA4t6nPzzTffWDwWQiA9PR1vv/02hg8fbpOCuYzqDsU6KNjnhoiISAYtCm7uu+8+i8eSJCEwMBC33XYbli9fbotyuY7qPjc6oeBoKSIiIhm0KLjR6/W2LofrMutQzNiGiIjI/jhnrr2ZTeLHZikiIiL7a1Fw8+CDD+L111+vs/2NN97Aww8/3OpCuZTq4KYKbJYiIiKSQ4uCm927d2PcuHF1to8dOxa7d+9udaFciqlDMZuliIiI5NCi4KaoqAhqtbrOdjc3NxQUFLS6UC5FXzNaikPBiYiI7K9FwU3fvn2xYcOGOtvXr1+PmJiYVhfKpeg5FJyIiEhOLRottXjxYjzwwANITU3FbbfdBgBITk7GZ599hi+++MKmBXR6ZpP4sc8NERGR/bUouBk/fjy++uorvPrqq9i4cSM8PDzQr18//Pjjj7j11lttXUbnZrb8AmMbIiIi+2tRcAMAd911F+666y5blsU1CcOcQFWCzVJERERyaFGfm99++w179+6ts33v3r3Yv39/qwvlUsznuWHqhoiIyO5aFNzMmjULV65cqbP96tWrmDVrVqsL5VI4QzEREZGsWhTcnDx5EgMHDqyzfcCAATh58mSzj/fOO+8gMjIS7u7uGDp0KPbt21fvvqNHj4YkSXVubbaJjKuCExERyapFwY1Go0FmZmad7enp6VCpmteNZ8OGDUhMTMTSpUtx8OBBxMbGIiEhAVlZWVb337RpE9LT002348ePQ6lUtt2Zkc0m8ZMY3BAREdldi4KbO++8EwsWLEB+fr5pW15eHl588UXccccdzTrWihUrMH36dEydOhUxMTFYs2YNPD09sXbtWqv7+/v7IyQkxHTbtm0bPD09225wY2qWUkDJdikiIiK7a9FoqTfffBOjRo1CREQEBgwYAAA4fPgwgoOD8cknnzT5OBUVFThw4AAWLFhg2qZQKBAfH4+UlJQmHeODDz7AxIkT4eXlZfX58vJylJeXmx7LPoOyxcKZ8r41ERFRe9SizE1YWBiOHj2KN954AzExMRg0aBBWrVqFY8eOITw8vMnHycnJgU6nQ3BwsMX24OBgZGRkNPr6ffv24fjx43jqqafq3ScpKQlardZ0a075bMKiQzGjGyIiIntr8Tw3Xl5eGDFiBLp06YKKigoAwP/+9z8AwD333GOb0jXigw8+QN++fTFkyJB691mwYAESExNNjwsKCuQNcDgUnIiISFYtCm4uXLiA+++/H8eOHYMkSRBCWHSW1el0TTpOQEAAlEplnc7JmZmZCAkJafC1xcXFWL9+PZYtW9bgfhqNBhqNpknlsYvqDsWGSfwcVwwiIqL2okXNUnPmzEFUVBSysrLg6emJ48ePY9euXRg8eDB27tzZ5OOo1WoMGjQIycnJpm16vR7JycmIi4tr8LVffPEFysvL8fjjj7ekCvLR14yW4lBwIiIi+2tR5iYlJQXbt29HQEAAFAoFlEolRowYgaSkJPz5z3/GoUOHmnysxMRETJ48GYMHD8aQIUOwcuVKFBcXY+rUqQCASZMmISwsDElJSRav++CDD3DfffehY8eOLamCfMzmueFQcCIiIvtrUXCj0+nQoUMHAIampWvXriE6OhoRERE4c+ZMs441YcIEZGdnY8mSJcjIyED//v3x3XffmToZp6WlQaGwTDCdOXMGP//8M3744YeWFF9epswNh4ITERHJoUXBTZ8+fXDkyBFERUVh6NCheOONN6BWq/HPf/4TXbt2bfbxZs+ejdmzZ1t9zlozV3R0NIQQzX4fhzDL3DC2ISIisr8WBTeLFi1CcXExAGDZsmW4++67MXLkSHTs2BEbNmywaQGdnqgZCs5mKSIiIvtrUXCTkJBgut+9e3ecPn0aubm58PPz4wW8tupmKT2bpYiIiGTR4nluavP397fVoVxLdbNUFZuliIiIZNGioeDUDMYOxYIzFBMREcmBwY29WXQoZnBDRERkbwxu7E2YTeLHdikiIiK7Y3Bjb6Z5biT2uSEiIpIBgxt7MzVLcSg4ERGRHBjc2Ju+Zp4bNksRERHZH4Mbe+MMxURERLJicGNvQg/AMIkfR0sRERHZH4Mbe6sObnRQQMHUDRERkd0xuLE3U+ZGgpKZGyIiIrtjcGNv1R2KBYeCExERyYLBjb0Zm6UEm6WIiIjkwODGzoRZsxQ7FBMREdkfgxs7MwY3gkPBiYiIZMHgxt6q+9zoIbFZioiISAYMbuzNfCg4m6WIiIjsjsGNnQk9h4ITERHJicGNvZn63EhgbENERGR/DG7sTJj63Ci4cCYREZEMGNzYG/vcEBERyYrBjb2ZNUsxcUNERGR/DG7sTFj0uWF0Q0REZG8MbuzNuLaUxI+aiIhIDrzi2lt15kZicENERCQLXnHtzbi2FIMbIiIiWfCKa2/VwQ0Y3BAREcmCV1x7MwU3SseWg4iIqJ1gcGNv1csvCI6UIiIikgWDG7tj5oaIiEhODG7sjX1uiIiIZMUrrr0xuCEiIpIVr7j2Vj2JH5cEJyIikgeDG3vjaCkiIiJZMbixNyEMP9ksRUREJAtece2OfW6IiIjkxCuunUnVfW4kBT9qIiIiOfCKa2/COIkf+9wQERHJgcGNnUkw9rnhaCkiIiI5MLixt+rMjcQ+N0RERLLgFdfehLHPDZuliIiI5MDgxs4kU58bftRERERy4BXX3jjPDRERkax4xbUzqXqeGw4FJyIikgevuPYkhKlZissvEBERyYPBjT0Zm6QASBwKTkREJAsGN/ZkzNoAzNwQERHJhMGNPZkHNxwKTkREJAsGN/ZUPccNwGYpIiIiuTC4sSezzI2CmRsiIiJZMLixJzZLERERyY7BjT2ZBTecoZiIiEgevOLak3mzFIMbIiIiWfCKa0/6muCGq4ITERHJg1dcezLL3EhK9rkhIiKSg8ODm3feeQeRkZFwd3fH0KFDsW/fvgb3z8vLw6xZsxAaGgqNRoOePXti69atMpW2maqDG52QoOBIcCIiIlmoHPnmGzZsQGJiItasWYOhQ4di5cqVSEhIwJkzZxAUFFRn/4qKCtxxxx0ICgrCxo0bERYWhsuXL8PX11f+wjdFdXCjhwJKRjdERESycGhws2LFCkyfPh1Tp04FAKxZswZbtmzB2rVrMX/+/Dr7r127Frm5ufjll1/g5uYGAIiMjJSzyM1TPYmfHhIn8SMiIpKJw5qlKioqcODAAcTHx9cURqFAfHw8UlJSrL7mm2++QVxcHGbNmoXg4GD06dMHr776KnQ6ndX9AaC8vBwFBQUWN9lUZ24EJCgY3BAREcnCYcFNTk4OdDodgoODLbYHBwcjIyPD6msuXLiAjRs3QqfTYevWrVi8eDGWL1+OV155pd73SUpKglarNd3Cw8NtWo8GGfvcQAElYxsiIiJZOLxDcXPo9XoEBQXhn//8JwYNGoQJEyZg4cKFWLNmTb2vWbBgAfLz8023K1euyFdgsz43zNwQERHJw2F9bgICAqBUKpGZmWmxPTMzEyEhIVZfExoaCjc3NyjNhlX37t0bGRkZqKiogFqtrvMajUYDjUZj28I3ld6sWYodiomIiGThsMyNWq3GoEGDkJycbNqm1+uRnJyMuLg4q68ZPnw4zp8/D73Z5Hhnz55FaGio1cDG4UyZGw4FJyIikotDm6USExPxf//3f/j3v/+NU6dOYebMmSguLjaNnpo0aRIWLFhg2n/mzJnIzc3FnDlzcPbsWWzZsgWvvvoqZs2a5agqNMy8zw2jGyIiIlk4dCj4hAkTkJ2djSVLliAjIwP9+/fHd999Z+pknJaWBoWiJv4KDw/H999/j2effRb9+vVDWFgY5syZgxdeeMFRVWiYWeaGQ8GJiIjkIQkhhKMLIaeCggJotVrk5+fDx8fHvm+WcQxYMwJZwhdvDfgWr9zX177vR0RE5KKac/12qtFSTscsc6Nk5oaIiEgWDG7syazPDZuliIiI5MHgxp7MZihmh2IiIiJ5MLixp+oh63quCk5ERCQbBjf2ZD5DMaMbIiIiWTC4sSezPjdcfoGIiEgeDG7syWJVcAeXhYiIqJ1gcGNPHApOREQkOwY39iR0AAx9bjgUnIiISB4MbuzJrEMxh4ITERHJg8GNPXFVcCIiItkxuLGn6mW79JA4FJyIiEgmDG7sSW/scyNxKDgREZFMGNzYk2kouIKjpYiIiGTC4MaeLBbOdHBZiIiI2gkGN/Zk0aGY0Q0REZEcGNzYU/U8N1wVnIiISD4MbuzJmLkRCg4FJyIikgmDG3uqHgqu41BwIiIi2TC4sSO9vmb5hZ7BHRxcGiIiovaBwY0d/Z5bBABQKBToH+7r2MIQERG1EypHF8DVXMsrxfksQ1CTdSEHXQBoPTVwUzKOJCIikgODGxsqLq/CHSt2objC0Bz1sDIHD7kBft7uDi4ZERFR+8HgxoYyC8pQXKGDQgJ6hfigc7kGKAGCtZ6OLhoREVG7weDGhkqqMzaBHTTYOmcksP8c8C3gpuLHTEREJBd2BLEhY3Djpa4OZqrnueHaC0RERPJhcGNDxRVVAABPjdKwoXqeG0hKB5WIiIio/WFwY0Ml5YbMjWedzA0/ZiIiIrnwqmtDpsyN2pi5YXBDREQkN151bai0dp+b6hmKGdwQERHJh1ddG2LmhoiIyPF41bUhY58bL02tPjcKdigmIiKSC4MbGzJmbjzqZG44FJyIiEguDG5sqKbPjTG4YZ8bIiIiufGqa0PGNaVqhoIb57nhx0xERCQXXnVtqKTc0CzlpandLMU+N0RERHJhcGNDNX1uOIkfERGRo/Cqa0N1+txwnhsiIiLZ8aprQ3X73DBzQ0REJDdedW3I2OemziR+nOeGiIhINgxubMiYuanboZjz3BAREcmFwY0NlbJZioiIyOF41bWRiio9KnSGYMaLwQ0REZHD8KprI8asDWBt+QX2uSEiIpILgxsbMc5x46aUoFZVf6zM3BAREcmOV10bKand3wbgPDdEREQOwKuujZRUZ25ME/gBzNwQERE5AK+6NlKp08NLrYSXxixzw+CGiIhIdqrGd6GmGBThjxPLxkAYVwIHzCbxY3BDREQkF151bUwyn7DPGOgwc0NERCQbXnXtSbBDMRERkdx41bUn9rkhIiKSHa+69sRJ/IiIiGTH4MaemLkhIiKSHa+69sRJ/IiIiGTHq649mTI3UsP7ERERkc0wuLEn0zw37HNDREQklzYR3LzzzjuIjIyEu7s7hg4din379tW770cffQRJkixu7u7uMpa2GTjPDRERkewcftXdsGEDEhMTsXTpUhw8eBCxsbFISEhAVlZWva/x8fFBenq66Xb58mUZS9wMnOeGiIhIdg6/6q5YsQLTp0/H1KlTERMTgzVr1sDT0xNr166t9zWSJCEkJMR0Cw4OlrHEzcDRUkRERLJz6FW3oqICBw4cQHx8vGmbQqFAfHw8UlJS6n1dUVERIiIiEB4ejnvvvRcnTpyod9/y8nIUFBRY3GTDeW6IiIhk59DgJicnBzqdrk7mJTg4GBkZGVZfEx0djbVr1+Lrr7/Gp59+Cr1ej2HDhuH333+3un9SUhK0Wq3pFh4ebvN61IuZGyIiItk53VU3Li4OkyZNQv/+/XHrrbdi06ZNCAwMxPvvv291/wULFiA/P990u3LlinyF5Tw3REREslM58s0DAgKgVCqRmZlpsT0zMxMhISFNOoabmxsGDBiA8+fPW31eo9FAo9G0uqwtwnluiIiIZOfQlIJarcagQYOQnJxs2qbX65GcnIy4uLgmHUOn0+HYsWMIDQ21VzFbjkPBiYiIZOfQzA0AJCYmYvLkyRg8eDCGDBmClStXori4GFOnTgUATJo0CWFhYUhKSgIALFu2DLfccgu6d++OvLw8/P3vf8fly5fx1FNPObIa1nESPyIiItk5PLiZMGECsrOzsWTJEmRkZKB///747rvvTJ2M09LSoFDUZD5u3LiB6dOnIyMjA35+fhg0aBB++eUXxMTEOKoK9eM8N0RERLKThDC2nbQPBQUF0Gq1yM/Ph4+Pj+0OXFUOFFn2HcL6x4CMo8DE/wC97rLdexEREbUzzbl+Ozxz4zLSjwIfxFt/jpkbIiIi2TC4sRVJAlRW1rjyCQPCBstfHiIionaKwY2tdB4MLMpsfD8iIiKyK7aXEBERkUthcENEREQuhcENERERuRQGN0RERORSGNwQERGRS2FwQ0RERC6FwQ0RERG5FAY3RERE5FIY3BAREZFLYXBDRERELoXBDREREbkUBjdERETkUhjcEBERkUthcENEREQuReXoAshNCAEAKCgocHBJiIiIqKmM123jdbwh7S64KSwsBACEh4c7uCRERETUXIWFhdBqtQ3uI4mmhEAuRK/X49q1a+jQoQMkSbLpsQsKChAeHo4rV67Ax8fHpsd2NFeuG+Da9WPdnJcr18+V6wa4dv0cVTchBAoLC9GpUycoFA33qml3mRuFQoHOnTvb9T18fHxc7pfZyJXrBrh2/Vg35+XK9XPlugGuXT9H1K2xjI0ROxQTERGRS2FwQ0RERC6FwY0NaTQaLF26FBqNxtFFsTlXrhvg2vVj3ZyXK9fPlesGuHb9nKFu7a5DMREREbk2Zm6IiIjIpTC4ISIiIpfC4IaIiIhcCoMbIiIicikMbmzknXfeQWRkJNzd3TF06FDs27fP0UVqkZdeegmSJFncevXqZXq+rKwMs2bNQseOHeHt7Y0HH3wQmZmZDixx/Xbv3o3x48ejU6dOkCQJX331lcXzQggsWbIEoaGh8PDwQHx8PM6dO2exT25uLh577DH4+PjA19cXTz75JIqKimSshXWN1W3KlCl1vscxY8ZY7NNW65aUlISbb74ZHTp0QFBQEO677z6cOXPGYp+m/B6mpaXhrrvugqenJ4KCgvDcc8+hqqpKzqpY1ZT6jR49us739/TTT1vs0xbr995776Ffv36myd3i4uLwv//9z/S8M39vQOP1c9bvzZrXXnsNkiRh7ty5pm1O9f0JarX169cLtVot1q5dK06cOCGmT58ufH19RWZmpqOL1mxLly4VN910k0hPTzfdsrOzTc8//fTTIjw8XCQnJ4v9+/eLW265RQwbNsyBJa7f1q1bxcKFC8WmTZsEALF582aL51977TWh1WrFV199JY4cOSLuueceERUVJUpLS037jBkzRsTGxopff/1V/PTTT6J79+7i0UcflbkmdTVWt8mTJ4sxY8ZYfI+5ubkW+7TVuiUkJIgPP/xQHD9+XBw+fFiMGzdOdOnSRRQVFZn2aez3sKqqSvTp00fEx8eLQ4cOia1bt4qAgACxYMECR1TJQlPqd+utt4rp06dbfH/5+fmm59tq/b755huxZcsWcfbsWXHmzBnx4osvCjc3N3H8+HEhhHN/b0I0Xj9n/d5q27dvn4iMjBT9+vUTc+bMMW13pu+PwY0NDBkyRMyaNcv0WKfTiU6dOomkpCQHlqplli5dKmJjY60+l5eXJ9zc3MQXX3xh2nbq1CkBQKSkpMhUwpapHQDo9XoREhIi/v73v5u25eXlCY1GIz777DMhhBAnT54UAMRvv/1m2ud///ufkCRJXL16VbayN6a+4Obee++t9zXOUjchhMjKyhIAxK5du4QQTfs93Lp1q1AoFCIjI8O0z3vvvSd8fHxEeXm5vBVoRO36CWG4SJpfVGpzpvr5+fmJf/3rXy73vRkZ6yeEa3xvhYWFokePHmLbtm0W9XG274/NUq1UUVGBAwcOID4+3rRNoVAgPj4eKSkpDixZy507dw6dOnVC165d8dhjjyEtLQ0AcODAAVRWVlrUtVevXujSpYvT1fXixYvIyMiwqItWq8XQoUNNdUlJSYGvry8GDx5s2ic+Ph4KhQJ79+6VvczNtXPnTgQFBSE6OhozZ87E9evXTc85U93y8/MBAP7+/gCa9nuYkpKCvn37Ijg42LRPQkICCgoKcOLECRlL37ja9TNat24dAgIC0KdPHyxYsAAlJSWm55yhfjqdDuvXr0dxcTHi4uJc7nurXT8jZ//eZs2ahbvuusviewKc7++u3S2caWs5OTnQ6XQWXyYABAcH4/Tp0w4qVcsNHToUH330EaKjo5Geno6//vWvGDlyJI4fP46MjAyo1Wr4+vpavCY4OBgZGRmOKXALGctr7XszPpeRkYGgoCCL51UqFfz9/dt8fceMGYMHHngAUVFRSE1NxYsvvoixY8ciJSUFSqXSaeqm1+sxd+5cDB8+HH369AGAJv0eZmRkWP1ujc+1FdbqBwB//OMfERERgU6dOuHo0aN44YUXcObMGWzatAlA267fsWPHEBcXh7KyMnh7e2Pz5s2IiYnB4cOHXeJ7q69+gHN/bwCwfv16HDx4EL/99lud55zt747BDVkYO3as6X6/fv0wdOhQRERE4PPPP4eHh4cDS0bNMXHiRNP9vn37ol+/fujWrRt27tyJ22+/3YEla55Zs2bh+PHj+Pnnnx1dFLuor34zZsww3e/bty9CQ0Nx++23IzU1Fd26dZO7mM0SHR2Nw4cPIz8/Hxs3bsTkyZOxa9cuRxfLZuqrX0xMjFN/b1euXMGcOXOwbds2uLu7O7o4rcZmqVYKCAiAUqms02M8MzMTISEhDiqV7fj6+qJnz544f/48QkJCUFFRgby8PIt9nLGuxvI29L2FhIQgKyvL4vmqqirk5uY6XX27du2KgIAAnD9/HoBz1G327Nn49ttvsWPHDnTu3Nm0vSm/hyEhIVa/W+NzbUF99bNm6NChAGDx/bXV+qnVanTv3h2DBg1CUlISYmNjsWrVKpf53uqrnzXO9L0dOHAAWVlZGDhwIFQqFVQqFXbt2oW33noLKpUKwcHBTvX9MbhpJbVajUGDBiE5Odm0Ta/XIzk52aId1lkVFRUhNTUVoaGhGDRoENzc3CzqeubMGaSlpTldXaOiohASEmJRl4KCAuzdu9dUl7i4OOTl5eHAgQOmfbZv3w69Xm86aTmL33//HdevX0doaCiAtl03IQRmz56NzZs3Y/v27YiKirJ4vim/h3FxcTh27JhFALdt2zb4+PiYmhAcpbH6WXP48GEAsPj+2mr9atPr9SgvL3f6760+xvpZ40zf2+23345jx47h8OHDptvgwYPx2GOPme471fcna/dlF7V+/Xqh0WjERx99JE6ePClmzJghfH19LXqMO4u//OUvYufOneLixYtiz549Ij4+XgQEBIisrCwhhGEoYJcuXcT27dvF/v37RVxcnIiLi3Nwqa0rLCwUhw4dEocOHRIAxIoVK8ShQ4fE5cuXhRCGoeC+vr7i66+/FkePHhX33nuv1aHgAwYMEHv37hU///yz6NGjR5sYLt1Q3QoLC8W8efNESkqKuHjxovjxxx/FwIEDRY8ePURZWZnpGG21bjNnzhRarVbs3LnTYkhtSUmJaZ/Gfg+NQ1LvvPNOcfjwYfHdd9+JwMDANjHktrH6nT9/Xixbtkzs379fXLx4UXz99deia9euYtSoUaZjtNX6zZ8/X+zatUtcvHhRHD16VMyfP19IkiR++OEHIYRzf29CNFw/Z/7e6lN79JczfX8Mbmxk9erVokuXLkKtVoshQ4aIX3/91dFFapEJEyaI0NBQoVarRVhYmJgwYYI4f/686fnS0lLxzDPPCD8/P+Hp6Snuv/9+kZ6e7sAS12/Hjh0CQJ3b5MmThRCG4eCLFy8WwcHBQqPRiNtvv12cOXPG4hjXr18Xjz76qPD29hY+Pj5i6tSporCw0AG1sdRQ3UpKSsSdd94pAgMDhZubm4iIiBDTp0+vE2y31bpZqxcA8eGHH5r2acrv4aVLl8TYsWOFh4eHCAgIEH/5y19EZWWlzLWpq7H6paWliVGjRgl/f3+h0WhE9+7dxXPPPWcxX4oQbbN+06ZNExEREUKtVovAwEBx++23mwIbIZz7exOi4fo58/dWn9rBjTN9f5IQQsiXJyIiIiKyL/a5ISIiIpfC4IaIiIhcCoMbIiIicikMboiIiMilMLghIiIil8LghoiIiFwKgxsiIiJyKQxuiKjd27lzJyRJqrNuDhE5JwY3RERE5FIY3BAREZFLYXBDRA6n1+uRlJSEqKgoeHh4IDY2Fhs3bgRQ02S0ZcsW9OvXD+7u7rjllltw/Phxi2N8+eWXuOmmm6DRaBAZGYnly5dbPF9eXo4XXngB4eHh0Gg06N69Oz744AOLfQ4cOIDBgwfD09MTw4YNw5kzZ+xbcSKyCwY3RORwSUlJ+Pjjj7FmzRqcOHECzz77LB5//HHs2rXLtM9zzz2H5cuX47fffkNgYCDGjx+PyspKAIag5JFHHsHEiRNx7NgxvPTSS1i8eDE++ugj0+snTZqEzz77DG+99RZOnTqF999/H97e3hblWLhwIZYvX479+/dDpVJh2rRpstSfiGyLC2cSkUOVl5fD398fP/74I+Li4kzbn3rqKZSUlGDGjBn4wx/+gPXr12PChAkAgNzcXHTu3BkfffQRHnnkETz22GPIzs7GDz/8YHr9888/jy1btuDEiRM4e/YsoqOjsW3bNsTHx9cpw86dO/GHP/wBP/74I26//XYAwNatW3HXXXehtLQU7u7udv4UiMiWmLkhIoc6f/48SkpKcMcdd8Db29t0+/jjj5Gammrazzzw8ff3R3R0NE6dOgUAOHXqFIYPH25x3OHDh+PcuXPQ6XQ4fPgwlEolbr311gbL0q9fP9P90NBQAEBWVlar60hE8lI5ugBE1L4VFRUBALZs2YKwsDCL5zQajUWA01IeHh5N2s/Nzc10X5IkAIb+QETkXJi5ISKHiomJgUajQVpaGrp3725xCw8PN+3366+/mu7fuHEDZ8+eRe/evQEAvXv3xp49eyyOu2fPHvTs2RNKpRJ9+/aFXq+36MNDRK6LmRsicqgOHTpg3rx5ePbZZ6HX6zFixAjk5+djz5498PHxQUREBABg2bJl6NixI4KDg7Fw4UIEBATgvvvuAwD85S9/wc0334yXX34ZEyZMQEpKCt5++228++67AIDIyEhMnjwZ06ZNw1tvvYXY2FhcvnwZWVlZeOSRRxxVdSKyEwY3RORwL7/8MgIDA5GUlIQLFy7A19cXAwcOxIsvvmhqFnrttdcwZ84cnDt3Dv3798d///tfqNVqAMDAgQPx+eefY8mSJXj55ZcRGhqKZcuWYcqUKab3eO+99/Diiy/imWeewfXr19GlSxe8+OKLjqguEdkZR0sRUZtmHMl048YN+Pr6Oro4ROQE2OeGiIiIXAqDGyIiInIpbJYiIiIil8LMDREREbkUBjdERETkUhjcEBERkUthcENEREQuhcENERERuRQGN0RERORSGNwQERGRS2FwQ0RERC6FwQ0RERG5lP8PBEB94XTFvvUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIrcCZ8P2t4N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "1535c3b0-6a24-4633-fe04-7d1922dd070d"
      },
      "source": [
        "### 13. Plot code for the model loss. You can refer to the plot code for model accuracy above.\n",
        "plt.plot(output.history['loss'])\n",
        "plt.plot(output.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "#plt.savefig('loss.png',dpi=100) #to save the image\n",
        "plt.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KTWzuJM12t4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171d1693-ec26-4c58-b223-8a873c3b84d4"
      },
      "source": [
        "### 14. What is the purpose of evaluating the model on the test dataset?\n",
        "\n",
        "#model.load_weights(model_loc+\"heart_disease_best_model.hdf5\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[0], scores[0]))\n",
        "print(\"loss:\", round(scores[0],2))\n",
        "\n",
        "# The purpose of evaluating the model on the test dataset is to assess\n",
        "# its performance and generalization ability on unseen data that was not\n",
        "# used during training or validation."
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1485 - acc: 0.8352\n",
            "\n",
            "acc: 83.52%\n",
            "loss: 0.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNYy0CRt2t4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948bea6f-c488-479a-9d96-bb0f2105de2d"
      },
      "source": [
        "#Display detailed prediction\n",
        "pred = model.predict(x_test)\n",
        "y = np.round(pred).astype(\"int16\")\n",
        "idx = 0\n",
        "ps = 0\n",
        "fl = 0\n",
        "for x in pred:\n",
        "    if y_test[idx]==y[idx]:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\"Result: \\033[92mPass\")\n",
        "        ps = ps+1\n",
        "    else:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\" Result: \\033[91mFail\")\n",
        "        fl = fl+1\n",
        "    idx = idx + 1\n",
        "print(\"\\033[30mRight Prediction :\",ps, \"Wrong Prediction :\",fl)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n",
            "\u001b[30mNo: 1 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 2 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 3 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 4 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 5 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 6 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 7 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 8 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 9 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 10 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 11 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 12 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 13 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 14 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 15 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 16 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 17 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 18 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 19 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 20 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 21 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 22 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 23 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 24 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 25 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 26 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 27 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 28 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 29 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 30 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 31 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 32 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 33 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 34 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 35 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 36 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 37 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 38 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 39 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 40 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 41 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 42 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 43 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 44 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 45 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 46 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 47 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 48 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 49 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 50 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 51 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 52 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 53 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 54 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 55 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 56 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 57 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 58 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 59 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 60 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 61 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 62 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 63 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 64 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 65 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 66 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 67 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 68 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 69 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 70 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 71 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 72 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 73 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 74 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 75 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 76 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 77 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 78 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 79 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 80 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 81 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 82 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 83 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 84 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 85 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 86 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 87 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 88 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 89 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 90 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 91 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mRight Prediction : 76 Wrong Prediction : 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHQBXNX5aYcn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "ba520755-eab9-42f4-f76c-5ca42d240b50"
      },
      "source": [
        "### 15. What is Confusion Matrix and why you need it? Explain TP, FP, FN, TN.\n",
        "### 16. Explain the classification report produce.\n",
        "\n",
        "y_pred = y\n",
        "y_true = y_test\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "#cm = confusion_matrix(y_true, y_pred, labels=labels.astype('int'))\n",
        "f, ax=plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(cm,annot=True,linewidths=1.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()\n",
        "print()\n",
        "print(classification_report(y_true, y_pred, labels=[0,1]))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81        41\n",
            "           1       0.84      0.86      0.85        50\n",
            "\n",
            "    accuracy                           0.84        91\n",
            "   macro avg       0.83      0.83      0.83        91\n",
            "weighted avg       0.83      0.84      0.83        91\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Confusion Matrix is a performance measurement technique for machine learning classification algorithms. It is a square matrix where the rows represent the actual classes, and the columns represent the predicted classes. Each cell in the matrix represents the count of instances where the actual class matches the predicted class."
      ],
      "metadata": {
        "id": "AOkdTv02v56Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "True Positive (TP): Instances where the model correctly predicts the positive class.\n",
        "\n",
        "False Positive (FP): Instances where the model incorrectly predicts the positive class when the actual class is negative. Also known as Type I error.\n",
        "\n",
        "False Negative (FN): Instances where the model incorrectly predicts the negative class when the actual class is positive. Also known as Type II error.\n",
        "\n",
        "True Negative (TN): Instances where the model correctly predicts the negative class."
      ],
      "metadata": {
        "id": "EbmfuJ_8wAUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For class 0:\n",
        "\n",
        "The Precision is 0.82, which means that 82% of instances predicted as class 0 are actually class 0.\n",
        "\n",
        "The Recall is 0.80, indicating that the model correctly identifies 80% of all actual class 0 instances.\n",
        "\n",
        "F1-score is 0.81, which is the harmonic mean of precision and recall for class 0.\n",
        "\n",
        "Support: 41, meaning that there are 41 instances of class 0 in the dataset.\n",
        "\n",
        "<hr>\n",
        "\n",
        "For class 1:\n",
        "\n",
        "Precision is 0.84, which means that 84% of instances predicted as class 1 are actually class 1.\n",
        "\n",
        "Recall is 0.86, indicating that the model correctly identifies 86% of all actual class 1 instances.\n",
        "\n",
        "F1-score is 0.85, which is the harmonic mean of precision and recall for class 1.\n",
        "\n",
        "Support is 50, meaning that there are 50 instances of class 1 in the dataset.\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "Accuracy is 0.84, indicating that the overall correctness of the model's predictions is 84%.\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "Macro average is 0.83, which is the average of precision, recall, and F1-score calculated independently for each class.\n",
        "\n",
        "The weighted average precision is 0.83, recall is 0.84, and F1-score is 0.83."
      ],
      "metadata": {
        "id": "EX8mcz_rwPTr"
      }
    }
  ]
}
